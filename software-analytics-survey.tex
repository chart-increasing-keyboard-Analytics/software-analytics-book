\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={A Literature Survey of Software Analytics},
            pdfauthor={IN4334 2018 TU Delft},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{A Literature Survey of Software Analytics}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{IN4334 2018 TU Delft}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{2018-10-07}

\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\chapter{Preamble}\label{intro}

The book you see in front of you is the outcome of an eight week seminar
run by the Software Engineering Research Group (SERG) at TU Delft. We
have split up the novel area of Software Analytics into several sub
topics. Every chapter addresses one such sub-topic of Software Analytics
and is the outcome of a systematic literature review a laborious team of
3-4 students performed.

With this book, we hope to structure the new field of Software Analytics
and show how it is related to many long existing research fields.

\emph{The IN4334 -- Software Analytics class of 2018}

\section{License}\label{license}

\includegraphics{figures/cc-nc-sa.png} This book is copyrighted 2018 by
TU Delft and its respective authors and distributed under the
\href{https://creativecommons.org/licenses/by-nc-sa/4.0/}{CC BY-NC-SA
4.0 license}

\chapter{A contemporary view on Software
Analytics}\label{a-contemporary-view-on-software-analytics}

\section{What is Software Analytics?}\label{what-is-software-analytics}

\section{A list of Software Analytics
Sub-Topics}\label{a-list-of-software-analytics-sub-topics}

\chapter{Testing Analytics}\label{testing-analytics}

\section{Motivation}\label{motivation}

Testing is an important aspect in software engineering, as it forms the
first line of defence against the introduction of software
faults\cite{pinto2012understanding}. However, in practice it seems that
not all developers test actively. In this paper we will survey on the
use of testing and the tools that make this possible. We will also look
into the future development of tools that is done or required in order
to improve testing practices in real-world applications. The above
example could have been prevented by making tests but is not guaranteed
to do so. Testing is not the holy grail for completely removing all bugs
from a program but it can decrease the chances for a user to encounter a
bug. We believe that extra research is needed to ease the life of
developers by making testing more efficient, easier to maintain and more
effective. Therefore, we wanted to write a survey on the testing
behavior, current practices and future developments of testing. In order
to perform our survey, we formulated three Research Questions (RQs):

\begin{itemize}
\tightlist
\item
  \textbf{RQ1} How do developers currently test?
\item
  \textbf{RQ2} What state of the art technologies are being used?
\item
  \textbf{RQ3} What future developments can be expected? In this paper
  we will first elaborate on the research protocol that was used in
  order to find papers and extract information for the survey. Second,
  the actual findings for each of the research questions will be
  explained.
\end{itemize}

\section{Research protocol}\label{research-protocol}

For this paper, Kitchenham's survey method was applied. For this method,
a protocol has to be specified. This protocol is defined for the
research questions given above. Below the inclusion and exclusion
criteria are given, which helped finding the rightful papers. After
these criteria, the actual search for papers is described. The papers
that were found are listed and after they are tested against the
criteria that are given. The data that is extracted from these papers
are list afterward. Some papers that were left out will be listed and
the reasons for leaving them out will be given to make clear why some
papers do not meet the required desire.

Each of the papers found was tested using our inclusion and exclusion
criteria. These criteria were introduced to make sure the papers have
the information required to answser the RQs while also being relevant
with respect to their quality and age. Below a list of inclusion and
exclusion criteria is given. In general, for all criteria, the exclusion
criteria take precedence over inclusion criteria. The following
inclusion and exclusion criteria were used:

\begin{itemize}
\tightlist
\item
  Papers published before 2008 are excluded from the research, unless a
  reference/citation is used for an unchanged concept.
\item
  Papers referring to less than 15 other papers, excluding
  self-references, are excluded from the research.
\item
  Selected papers should have an abstract, introduction and conclusion
  section.
\item
  Papers stating the developers' testing behavior are included.
\item
  Papers stating the developers' problems related to testing are
  included.
\item
  Papers stating the technologies, related to testing analytics, which
  developers use are included.
\item
  Papers writing about the expected advantage of current findings in
  testing analytics are included.
\item
  Papers with recommendations for future development in the software
  testing field are included.
\end{itemize}

The papers used in this paper were found by using a given initial seed
of papers (query defined below as `Initial Paper Seed'). From this
initial seed of papers we used the keywords used by those papers to
construct queries, additionally the references (`referenced by') and the
citations (`cited in') of the papers were used to find papers. The query
row of the tables describing the references, as found below, indicates
how a paper was found. For queries the default search sites were Scopus,
Google Scholar and Springer.

The keywords used to find papers were: software, test*, analytics,
test-suite, evolution, software development, computer science, software
engineering, risk-driven, survey software testing

The table below describes for each paper, which Query resulted in which
paper being found.

\begin{longtable}[]{@{}lll@{}}
\toprule
\begin{minipage}[b]{0.19\columnwidth}\raggedright\strut
Category\strut
\end{minipage} & \begin{minipage}[b]{0.41\columnwidth}\raggedright\strut
Reference\strut
\end{minipage} & \begin{minipage}[b]{0.32\columnwidth}\raggedright\strut
Query\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Test evolution\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{supportingtestsuite}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Google Scholar query: test-suite evolution\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Test evolution\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{pinto2013}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Referenced by: Understanding myths and realities of test-suite
evolution\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Test evolution\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{bevan2005}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Referenced by: Understanding myths and realities of test-suite
evolution\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Test evolution\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{pinto2012understanding}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Initial Paper Seed\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Co-evolution\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{marsavina2014}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Google Scholar keywords: Maintain developer tests, in `cited by' of
``Aiding Software Developers to Maintain Developer Tests'' on IEEE\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Co-evolution\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{zaidman2011studying}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Initial Paper Seed\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Co-evolution\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{greiler2013}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
In `cited by' of ``Understanding myths and realities of test-suite
evolution'' on Scopus\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Co-evolution\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{hurdugaci2012}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Keywords: Maintain developer tests, `cited by' in ``Studying the
co-evolution of production and test code in open source and industrial
developer test processes through repository mining'' on IEEE\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Production evolution\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{eick2001}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Referenced by: Testing analytics on software variability\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Production evolution\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
@leung2015testing\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Initial Paper Seed\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Test generation\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{robinson2011}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Referenced in Supporting Test Suite Evolution through Test Case
Adaptation\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Test generation\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{bowring2014obsidian}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Springer: Reverse search on ``Automatically generating maintainable
regression unit tests for programs''\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Test generation\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{shamshiri2018automatically}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Google Scholar query: Automatically generating unit tests\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Test generation\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
@dulz2013model\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Scopus query: ``software development'' AND Computer Science AND Software
Engineering\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Testing practices\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{GAROUSI20131354}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Google Scholar query: Survey software testing\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Testing practices\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{beller2017developer}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Initial Paper Seed\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Testing practices\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{beller2015}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
In `cited by' of ``Understanding myths and realities of test-suite
evolution''.\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Testing practices\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{moiz2017uncertainty}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Springer query: software testing\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Risk-driven testing\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{hemmati2018}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
In `cited by' of ``Test case analytics: Mining test case traces to
improve risk-driven testing''\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Risk-driven testing\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{schneidewind2007}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Scopus query: risk-driven testing\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Risk-driven testing\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{vernotte2015}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Scopus query: ``risk-driven'' AND testing\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Risk-driven testing\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{atifi2017}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
In `cited by' of ``Risk-driven software testing and reliability''\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.19\columnwidth}\raggedright\strut
Risk-driven testing\strut
\end{minipage} & \begin{minipage}[t]{0.41\columnwidth}\raggedright\strut
\citet{noor2015test}\strut
\end{minipage} & \begin{minipage}[t]{0.32\columnwidth}\raggedright\strut
Initial Paper Seed\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\subsection{Papers per research
question}\label{papers-per-research-question}

In this section, each of the papers is categorized with a corresponding
research question. In the table above, the categories per paper were
added based on their general topic. These broad topics will be assigned
to a corresponding research question. All papers per research question
are ordered on their relevance, which in most cases means that a newer
paper is considered as more relevant than an older paper. A lower
ranking may also be caused by a lower quality of writing (e.g.
\citet{greiler2013} in RQ2). The categorizations are based on the bullet
points extracted from each paper. These bullet points can be found below
in section \emph{`Extracted paper information'} below.

\begin{itemize}
\tightlist
\item
  \textbf{RQ1} (\emph{How do developers currently test?}):

  \begin{itemize}
  \tightlist
  \item
    \citet{beller2017developer}
  \item
    \citet{beller2015}
  \item
    \citet{marsavina2014}
  \item
    \citet{pinto2013}
  \item
    \citet{GAROUSI20131354}
  \item
    \citet{pinto2012understanding}
  \item
    \citet{zaidman2011studying}
  \end{itemize}
\item
  \textbf{RQ2} (\emph{What state of the art technologies are being
  used?}):

  \begin{itemize}
  \tightlist
  \item
    \citet{supportingtestsuite}
  \item
    \citet{vernotte2015}
  \item
    \citet{bowring2014obsidian}
  \item
    \citet{hurdugaci2012}
  \item
    \citet{robinson2011}
  \item
    \citet{greiler2013}
  \item
    \citet{dulz2013model}
  \item
    \citet{atifi2017}
  \item
    \citet{noor2015test}
  \end{itemize}
\item
  \textbf{RQ3} (\emph{What future developments can be expect?}):

  \begin{itemize}
  \tightlist
  \item
    \citet{hemmati2018}
  \item
    \citet{shamshiri2018automatically}
  \item
    \citet{vernotte2015}
  \item
    \citet{noor2015test}
  \item
    \citet{supportingtestsuite}
  \item
    \citet{bowring2014obsidian}
  \item
    \citet{leung2015testing}
  \item
    \citet{greiler2013}
  \item
    \citet{atifi2017}
  \end{itemize}
\end{itemize}

\section{Extracted paper information}\label{extracted-paper-information}

The papers retrieved using the research protocol are reviewed for their
quality and useful information is extracted to be able to answer the
research questions. This information can be found in this section as a
list of bullet-points. If a paper is perceived as `bad' or irrelevant
for answering the research questions, this is elaborated.

\subsection{Test evolution}\label{test-evolution}

Supporting Test Suite Evolution through Test Case Adaptation
(\citet{supportingtestsuite})

\begin{itemize}
\tightlist
\item
  Test case evolution.
\item
  Automatic test repairing using information available in existing test
  cases.
\item
  Identifies a set of common actions for adapting test cases by
  developers.
\item
  Properly repairs 90\% of the compilation errors addressed and covers
  the same amount of instructions.
\item
  Not all prototypes were tested.
\item
  Claims that many test cases designed for the early versions of the
  system become obsolete during the software lifecycle.
\item
  An approach is proposed for automatically repairing and generating
  test cases during software evolution.
\item
  This approach uses information available in existing test cases,
  defines a set of heuristics to repair test cases invalidated by
  changes in the software, and generate new test cases for evolved
  software.
\item
  The results show that the approach can effectively maintain evolving
  test suites, and perform well compared to competing approaches.
\item
  Frequent actions for adapting test cases that developers commonly
  adopt to repair and generate test cases are identified.
\item
  In general: automated test case evolution seems fairly possible. (in
  2012)
\end{itemize}

TestEvol: A tool for analyzing test-suite evolution (\citet{pinto2013})

\begin{itemize}
\tightlist
\item
  Test case evolution.
\item
  Tool for systematic investigating the evolution of the test-suite.
\item
  Motivation: understand test maintenance in general.
\item
  Only for Java and JUnit.
\end{itemize}

Facilitating software evolution research with kenyon (\citet{bevan2005})
This paper is too old based on our exclusion criteria.

Understanding myths and realities of test-suite evolution
(\citet{pinto2012understanding})

\begin{itemize}
\tightlist
\item
  Systematic measurement of how test-suites evolve
\item
  Test repairs occur in practice. avg 16 repairs per version
  --\textgreater{} often enough to warrant the development of automated
  techniques.
\item
  Test repairs are not the primary reason for test modification.
  Non-test repair related modifications occur about 4 times as
  frequently.
\item
  Only 10\% of the tests consider fixed assert tests (oracle tests)
\item
  Test repairs frequently consider repairs to method call chains.
\item
  Test deletions and additions are often due to refactoring
\item
  A considerable portion of the additions is due to augmenting tests to
  make it more *adequate.
\item
  General: automated techniques may be useful.
\end{itemize}

\subsection{Co-Evolution}\label{co-evolution}

Studying Fine-Grained Co-evolution Patterns of Production and Test Code
(\citet{marsavina2014})

\begin{itemize}
\tightlist
\item
  Co-evolution of production and test code.
\item
  Generally co-evolving test and production code is a difficult tass.
\item
  Mines fine-grained changes from the evolution of 5 open-source
  systems.
\item
  Also uses an association rule mining algorithm to generate
  co-evolution patterns.
\item
  The patterns are interpreted by performing a qualitative analysis.
\item
  Meant to gain a deeper understanding of the way in which tests evolve
  as a result of changes in the production classes and identify possible
  gaps to signal developers for missed production code parts that have
  not been addressed adequately by tests.
\item
  Some patterns that were found:
\item
  Tests are mostly removed when production classes they cover are
  deleted. Programmers are careful not to leave non-compiling tests.
\item
  Only limited effort is done on updating test cases after production
  classes are modified; tests are rarely changed when attributes or
  methods are changed in the production classes.
\item
  A pattern indicates that mostly when numerous condition related
  changes are made in the production methods, test cases are
  created/deleted in order to address the branches that were
  removed/added.
\item
  Test cases are rarely updated when changes related to attributes or
  methods are made in the production code.
\item
  Test methods are in several cases created/deleted when conditional
  statements are altered in the production code.
\item
  Future work should include the co-evolution patterns of different
  coding methodologies, for example, Test-Driven Development and their
  possible respective differences.
\item
  Future work should include intent-preserving techniques, which could
  help ensure test repairs address the same production code
  functionalities as before the tests were broken.
\end{itemize}

Studying the co-evolution of production and test code
(\citet{zaidman2011studying})

\begin{itemize}
\tightlist
\item
  Testing is phased and co-evolution is synchronous
\item
  No increase in testing activity before major releases. Intense phases
  were detected.
\item
  Evidence for TDD discovered in 2/6 test cases.
\item
  The fraction of test code (wrt prod code) increases as coverage
  increases
\end{itemize}

Strategies for avoiding text fixture smells during software evolution
(\citet{greiler2013})

\begin{itemize}
\tightlist
\item
  Knowledge about how and when smells in test fixtures are produced.
\item
  Test fixture smells do not continuously develop over time.
\item
  A correlation between the number of tests and smells.
\item
  Few test cases contribute to the majority of the smells.
\item
  Not the highest quality paper, the title even contains a typo, where
  `text' should be `test'.
\end{itemize}

Aiding Software Developers to Maintain Developer Tests
(\citet{hurdugaci2012})

\begin{itemize}
\tightlist
\item
  Support for co-evolution of testing code with production code.
\item
  Introduces TestNForce (Visual Studio only), a tool to help developers
  to identify unit tests that need to be altered and executed after code
  change.
\item
  Gives a broad explanation for the need for the co-evolution of test
  code.
\item
  Three scenarios: show covering tests, enforcing self-contained commits
  and what tests need to run?
\item
  Used an experimental setup with only eight participants from the Delft
  University of Technology of which two participants did not use Unit
  testing. Hard to generalize.
\item
  On average, the participants considered 80 code coverage as ``good''.
\end{itemize}

\subsection{Production evolution}\label{production-evolution}

Does code decay? Assessing the evidence from change management data
(\citet{eick2001}) This paper is too old based on our exclusion
criteria.

Testing analytics on software variability (\citet{leung2015testing})

\begin{itemize}
\tightlist
\item
  Variability-aware testing.
\item
  System integration testing has to be manually executed to evaluate the
  system's compliance with its specified requirement and performance.
\item
  Aids testers and developers to reduce their product time-to-market by
  utilizing historical testing results and similarity among systems.
\end{itemize}

\subsection{Test generation}\label{test-generation}

Scaling up automated test generation: Automatically generating
maintainable regression unit tests for programs (\citet{robinson2011})

\begin{itemize}
\tightlist
\item
  A system that has good coverage and mutation kill score, made readable
  code and required few edits as the system under test evolved. (stable)
\item
  Statement: The costs of unit tests are not perceived to outweigh the
  benefits.
\item
  Previous techniques: hard to understand / maintain / brittle and only
  tested on libraries → not real software development code.
\item
  They claim they made a pretty well working test-generation tool.
\end{itemize}

Obsidian: Pattern-Based Unit Test Implementations
(\citet{bowring2014obsidian})

\begin{itemize}
\tightlist
\item
  A tool that generates the templates for tests: guarantee compilation,
  support exception handling, find suitable location\ldots{} etc.
\item
  Developers still need to fix the oracle tests, but the
  implementation/template is there.
\item
  Looks at the context in order to decide what template to use.
\item
  Distinguishes implementations from test cases
\end{itemize}

How Do Automatically Generated Unit Tests Influence Software
Maintenance? (\citet{shamshiri2018automatically})

\begin{itemize}
\tightlist
\item
  Automatically generated tests are usually not based on realistic
  scenarios, and are therefore generally considered to be less readable.
\item
  Every time a test fails, a developer has to decide whether this
  failure has revealed a regression fault in the program under test, or
  whether the test itself needs to be updated.
\item
  Whilst maintenance activities take longer when working with
  automatically generated tests, they found developers to be equally
  effective with manually written and automatically generated tests.
\item
  There is a need for research into the generation of more realistic
  tests.
\end{itemize}

Model-Based Strategies for Reducing the Complexity of Statistically
Generated Test Suites (\citet{dulz2013model})

\begin{itemize}
\tightlist
\item
  By directed adjusting specific probability values in the usage profile
  of a Markov chain usage model it is relatively easy to generate
  abstract test suites for different user classes and test purposes in
  an automated approach.
\item
  By using proper tools, like the TestUS Testplayer even less
  experienced test engineers will be able to efficiently generate
  abstract test cases and to graphically assess quality characteristics
  of different test suites.
\end{itemize}

\subsection{Testing Practices}\label{testing-practices}

A survey of software testing practices in Canada
(\citet{GAROUSI20131354})

\begin{itemize}
\tightlist
\item
  The importance of testing-related training is increasing
\item
  Functional and unit-testing receive the most effort and attention
\item
  The mutation testing approach is getting attention amongst Canadian
  firms
\item
  Test last approach is still dominant, few companies try TDD
\item
  In terms of popularity: NUnit and Web application testing overtook
  JUnit and IBM Rational tools
\item
  Coverage metrics, to most commonly used: branch and conditional
  coverage
\item
  Number of passing test / defects per day is used as the most popular
  metric in order to determine a release
\item
  Ratio of testers : developers is somewhere around 1:2 and 1:5. The
  total effort is estimated to be less than 40\%
\item
  More than 70\% of the respondents participated in a forum related to
  testing on a regular basis
\item
  In general: more attention to testing (in 2012)
\end{itemize}

Developer testing in the IDE: Patterns, beliefs and behavior
(\citet{beller2017developer})

\begin{itemize}
\tightlist
\item
  Java C\# developer testing behavior
\item
  Little support for TDD
\item
  Developers execute tests phased
\item
  Only half of the developers practice testing actively
\item
  Testing time is overestimated twofold.
\item
  12\% of the test cases show flaky behavior
\item
  Correlation between test flakiness and CI error-proneness?
\item
  Few (25\%) tests detect 75\% of the execution failures.
\item
  Tests and production code do not co-evolve gracefully.
\end{itemize}

When, how, and why developers (do not) test in their IDEs
(\citet{beller2015})

\begin{itemize}
\tightlist
\item
  Developers largely do not run tests in the IDE. However, when they do,
  they do it heftily.
\item
  Tests run in the IDE take a short amount of time
\item
  Developers run selective tests (often 1)
\item
  Most test executions fail
\item
  A typical reaction is to dive into offending code
\item
  TDD is not widely practiced, even by those who say they do (strict
  definition)
\item
  The way people test is different from how they believe they test.
\end{itemize}

Uncertainty in Software Testing (\citet{moiz2017uncertainty})

\begin{itemize}
\tightlist
\item
  Mechanisms are needed to address uncertainty in each of the
  deliverables produced during software development process. The
  uncertainty metrics can help in assessing the degree of uncertainty.
\end{itemize}

\subsection{Risk-driven testing}\label{risk-driven-testing}

Investigating NLP-Based Approaches for Predicting Manual Test Case
Failure (\citet{hemmati2018})

\begin{itemize}
\tightlist
\item
  System-level manual acceptance testing is one of the most expensive
  testing activities.
\item
  A new test case failure prediction approach is proposed, which does
  not rely on source code or specification of the software under test.
\item
  The approach uses basic Information Retrieval (IR) methods on the test
  case descriptions, written in natural language, based on the frequency
  of terms in the manual test scripts.
\item
  The test fail prediction is accurate and the NLP-based feature can
  improve the prediction models.
\item
  ``To the best of our knowledge, this work is the first use of NLP on
  manual test case scripts for test failure prediction and has shown
  promising results, which we are planning to replicate on different
  systems and expand on different NLP-based features to more accurately
  extract features keywords from test cases.''
\end{itemize}

Risk-driven software testing and reliability (\citet{schneidewind2007})

This paper is discarded from the survey, because it uses weak models to
validate the claims made and is too old based on our exclusion criteria.

Risk-driven vulnerability testing: Results from eHealth experiments
using patterns and model-based approach (\citet{vernotte2015})

\begin{itemize}
\tightlist
\item
  This paper introduces and reports on an original tooled risk-driven
  security testing process called Pattern-driven and Model-based
  Vulnerability Testing. This fully automated testing process, drawing
  on risk-driven strategies and Model-Based Testing (MBT) techniques,
  aims to improve the capability of detection of various Web application
  vulnerabilities, in particular SQL injections, Cross-Site Scripting,
  and Cross-Site Request Forgery.
\item
  An empirical evaluation, conducted on a complex and freely-accessible
  eHealth system developed by Info World, shows that this novel process
  is appropriate for automatically generating and executing risk-driven
  vulnerability test cases and is promising to be deployed for
  large-scale Web applications.
\end{itemize}

A comparative study of software testing techniques (\citet{atifi2017})

\begin{itemize}
\tightlist
\item
  They highlight two software testing techniques considered among the
  most used techniques to perform software tests, and then perform a
  comparative study of these techniques, the approaches that support
  studied techniques, and the tools used for each technique.
\item
  The first technique is Model-based-testing, the second Risk-based
  testing.
\end{itemize}

Test case analytics: Mining test case traces to improve risk-driven
testing (\citet{noor2015test})

\begin{itemize}
\tightlist
\item
  In risk-driven testing, test cases are generated and/or prioritized
  based on different risk measures. *The most basic risk measure would
  analyze the history of the software and assigns higher risk to the
  test cases that used to detect bugs in the past.
\item
  A new risk measure is defined which assigns a risk factor to a test
  case, if it is similar to a failing test case from history. *The new
  risk measure is by far more effective in identifying failing test
  cases compared to the traditional risk measure.
\item
  ``Though our initial and simple implementation in this paper was very
  promising, we are planning to investigate other similarity functions,
  specifically those that account for the method orders in the trace. In
  addition, this project is a sub-project of a bigger research on
  risk-driven model-based testing, where we are planning to extract
  specification models of the system and augment them with the
  similarity-based risk measures. Those models can later be used in both
  risk-driven test generation and prioritization.''
\end{itemize}

\chapter{Build analytics}\label{build-analytics}

\section{Motivation}\label{motivation-1}

Ideally, when building a project from source code to executable, the
process should be fast and without any errors. Unfortunately, this is
not always the case and automated builds results notify developers of
compile errors, missing dependencies, broken functionality and many
other problems. This chapter is aimed to give an overview of the effort
made in Build Analytics field and Continuous Integration (CI) as an
increasingly common development practice in many projects.

Continuous Integration in a term used in software engineering to
describe a practice of merging all developer working copies to a shared
mainline several times a day. CI is in general used together with
Version control System (VCS). Version Control System is an application
for revision control that ensures the managment of changes to documents,
source code and other collections of information.

Build analytics covers research done on data extracted from a build
process inside a project. This contains amongst others, build logs from
continuous integration such as Travis~CI\footnote{See
  \url{https://travis-ci.org/}}, Circle~CI\footnote{See
  \url{https://circleci.com/}}, Jenkins\footnote{See
  \url{https://jenkins.io/}}, AppVeyor\footnote{See~\url{https://www.appveyor.com/}}
and TeamCity\footnote{See \url{https://www.jetbrains.com/teamcity/}} or
surveys among developers about their usage of Continuous Integration or
build systems. This information is often paired with data from Version
Control Systems (VCS) such as Git.

In order to get a complete view of the current state of the build
analytics field, we ask the following research questions.

\textbf{RQ1}: What is the current state of the art in the field of build
analytics?

In order to answer to the first research question, we need to present
the current topics that are being explored in the build analytics domain
alogside with the research methods, tools and datasets acquired for the
problems in hand and aggregate and reflect about the main research
findings that the state-of-the-art papers display.

\textbf{RQ2}: What is the current state of practice in the field of
build analytics?

This section examines scientific papers to analyse the current trend of
build analytics in the software development industry. We look at the
popularity of CI in the industry as \citet{hilton2016usage} describes.
In addition, it also explores the increase in the use of Continuous
Integration (CI) by discussing its ample benefits as
\citet{fowler2006continuous} presents. Furthermore, it will discuss the
practices used by engineers in the industry to ensure that their code is
improving and not decaying.

\textbf{RQ3}: What future research can we expect in the field of build
analytics?

In this section we will explore where new challenges lie in the field of
build analytics. We will also show what open research items are
described in the papers. This section ends with research questions based
on the open research and challenges in current research.

\section{Research protocol}\label{build-analytics-research-protocol}

Using the initial seed consisting of \citet{bird2017predicting},
\citet{beller2017oops}, \citet{rausch2017empirical},
\citet{beller2017travistorrent}, \citet{pinto2018work},
\citet{zhao2017impact}, \citet{widder2018m} and \citet{hilton2016usage}
we used references to find new papers to analyze. Moreover, we used
academical search engines like \emph{GoogleScholar} to perform a keyword
based search for other relevant build analytics domain papers. The
keywords used were: build analytics, machine learning, build time,
prediction, continuous integration, build failures, active learning,
build errors, mining, software repositories, open-source software.

\begin{longtable}[]{@{}llll@{}}
\toprule
Paper with reference & Source & RQ & Notes\tabularnewline
\midrule
\endhead
1. \citet{bird2017predicting} & Initial seed & RQ1 & 1\tabularnewline
2. \citet{beller2017oops} & Initial seed & RQ3 &\tabularnewline
3. \citet{rausch2017empirical} & Initial seed & RQ2 &\tabularnewline
4. \citet{beller2017travistorrent} & Initial seed & RQ2 &\tabularnewline
5. \citet{pinto2018work} & Initial seed & RQ3 &\tabularnewline
6. \citet{zhao2017impact} & Initial seed & RQ3 & 2\tabularnewline
7. \citet{widder2018m} & Initial seed & RQ1 &\tabularnewline
8. \citet{hilton2016usage} & Initial seed & RQ2 &\tabularnewline
9. \citet{vassallo2017tale} & Ref 2 & - & 3\tabularnewline
11. \citet{hassan2018hirebuild} & Ref 4 & RQ1 &\tabularnewline
12. \citet{vassallo2018break} & Ref 2,3 & RQ1, RQ3 &\tabularnewline
13. \citet{zampetti2017open} & Ref by 12 & - & 3\tabularnewline
14. \citet{baltes2018no} & GScholar Search & RQ1, RQ3 & 4\tabularnewline
15. \citet{bisong2017built} & GScholar Search & RQ1, RQ3 &
5\tabularnewline
16. \citet{santolucito2018statically} & GScholar Search & RQ1 &
4\tabularnewline
17. \citet{ni2018acona} & GScholar Search & RQ1 & 6\tabularnewline
18. \citet{fowler2006continuous} & GScholar Search & RQ2 &
7\tabularnewline
19. \citet{stolberg2009enabling} & GScholar Search & RQ2 &
7\tabularnewline
\bottomrule
\end{longtable}

\textbf{Notes}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  US patent owned by Microsoft.
\item
  Collaboration between universities in China, The Netherlands and The
  USA.
\item
  Not included in this survey as it did not introduce a new technique or
  practice.
\item
  Using search term ``Github Continuous Integration''.
\item
  Using search term ``Predicting build time''
\item
  Using search term ``Predicting build failures''
\item
  Using search term ``Current practices in Continuous Integration''
\end{enumerate}

Most of the papers we found were linked to our research questions being
reference in the sections bellow. From the identified papers, we choose
to not include in our research two papers: \citet{vassallo2017tale} and
\citet{zampetti2017open}. \citet{vassallo2017tale} is a case study of
difference in failures on continuous integration between open source
software (OSS) and industrial software projects from ING Netherlands and
we consider that it does not fit in any of the research question our
chapter proposed. \citet{zampetti2017open} is again a case study of the
usage of static analysis tools in 20 Java open source software projects
hosted on GitHub that use Travic CI. Taking into account the small
generalization degree of the findings highlighted by the article, we
decide to remove this article from our research as well.

\section{Answers}\label{answers}

\textbf{RQ1}: What is the current state of the art in the field of build
analytics?

The current state-of-the-art in the build analytics domain refers to the
use of machine learning techniques to increase the productivity when
using Continuos Integration (CI), to generate constraints on the
configuration of the CI that could improve build success rate and to
predict build failures even for newer projects with less training data
available.

The papers identified using the research protocol defined in the
previous section that give us an overview of the current state of the
art in build analytics domain are:

\begin{itemize}
\tightlist
\item
  Hassan et al. 2018
\item
  Vassallo et al. 2018
\item
  Baltes et al. 2018
\item
  Bisong et al. 2017
\item
  Santolucito et al. 2018
\item
  Ni et al. 2018
\end{itemize}

The topics that are being explored are:

\begin{itemize}
\tightlist
\item
  the importance of the build process in a VCS project
  \citet{hassan2018hirebuild}
\item
  the impact factors of user satisfaction for using a CI tools
  \citet{widder2018m}
\item
  methods from helping the developer to fix bugs
  \citet{hassan2018hirebuild}, \citet{vassallo2018break}
\item
  predicting build time \citet{bisong2017built}
\item
  predicting build failures \citet{santolucito2018statically},
  \citet{ni2018acona}
\end{itemize}

The tools that are being proposed are:

\begin{itemize}
\tightlist
\item
  BART to help developers fix build errors by generating a summary of
  the failures with useful information, thus eliminating the need to
  browse error logs \citet{vassallo2018break}
\item
  HireBuild to automatically fix build failures based on previous
  changes \citet{hassan2018hirebuild}
\item
  VeriCI capable of checking the errors in CI configurations files
  before the developer pushes a commit and without needing to wait for
  the build result \citet{santolucito2018statically}
\item
  ACONA capable of predicting build failure in CI environment for newer
  projects with less data available \citet{ni2018acona}
\end{itemize}

\emph{Importance of the build process}

The build process is an important part of a project that uses VCS in the
way that based on the findings from \citet{hassan2018hirebuild} 22\% of
code commits include changes in build script files for either build
working or build fixing purposes.

\emph{CI users satisfaction}

Moreover, recent studies have focused on how satisfied the users of CI
tools are, one particular paper \citet{widder2018m} analyzing what
factors have an impact on abandonment of Travis~CI. The paper finds that
increased build complexity reduces the chance of abandonment, but larger
projects abandon at a higher rate and that a project's language has
significant but varying effect. A surprising result is that metrics of
configuration attempts and knowledge dispersion in the project do not
affect the rate of abandonment.

\emph{Patent for predicting build errors}

\citet{bird2017predicting} introduce a method for predicting sofware
build errors. This US patent is owned by Microsoft. Having logistic
regression as machine learning technique, the paper is able to compute
the probability of a build to fail. Using this method build errors can
be better anticipated, which decreases the time between working builds.

\emph{Predicting build time}

Another important aspect is the impact of CI on the development process
efficiency. One of the papers that adresses this matters is
\citet{bisong2017built}. This paper aims to find a balance between the
frequency of integration and developer's productivity by proposing
machine learning models that were able to predict the build taking
advantage of the 56 features presented in TravisTorrent build records.
Their models performed quite well with an R-Squared of around 80\%,
meaning that they were able to capture the variation of build time over
multiple projects. Their research could be useful on one hand for
software developers and project managers for a better time management
scheme and on the other hand for other researchers that may improve
their proposed models.

\emph{Predicting build failures}

Moreover, the usage of automation build tools introduces a delay in the
development cycle generated by the waiting time until the build finish
successfully. One of the most recent papers analyzed
\citet{santolucito2018statically} presents a tool VeriCI capable of
checking the errors in CI configurations files before the developer
pushes a commit and without needing to wait for the build result. This
paper focuses on prediction of build failure without using metadata like
number of commits, code churn also in the learning process, but relying
on the actual user programs and configuration scripts. This fact makes
the identification of the error cause possible. VeriCI achieves 83\%
accuracy of predicting build failure on real data from GitHub projects
and 30-48\% of time the error justification provided by the tool matched
the actual error cause. These results seem promising, but there is a
need in focusing more on producing the error justification fact that
could make the use of machine learning tools in real build analytics
tools achievable and tolerated.

\emph{Prediction with less data available}

Even if there were considerable efforts in developing powerful and
accurate machine learning models for predicting the outcome of builds,
most of this techniques cannot be trained properly without large project
past data. The problem that resulted from this is newer project being
unable to take advantage of the research conducted before and having to
wait until enough data from their project is generated in order to
sufficiently train machine learning models from predicting the build
outcome. The most recent paper of this survey which is only published as
a poster in June 2018, \citet{ni2018acona}, addresses the problem of
build failure prediction in CI environment for newer projects with less
data available. It is using already trained models from other project
with more data available and combined them by the means of active
learning in order to find which of that models generalized better from
the problem in hand and to update the models weights accordingly. It is
also aimed to cut the expense that CI introduce by reducing the label
data necessarily for training. Even if the method seems promising, the
results presented in the poster shows an F-Measure (harmonic average of
recall and precision) of around 40\% that could be better improved.

\textbf{RQ2}: What is the current state of practice in the field of
build analytics?

Continuous Integration (CI) is a development practise that requires
developers to integrate code into a share repository several times a
day. Each check-in is then verified by an automated build which allows
engineers to detect any bugs early.

An overview of Continuous Integration evolution from the introduction of
the term to the current practices can be seen in the figure bellow:

\begin{figure}
\centering
\includegraphics{figures/Chapter3/state_pr.png}
\caption{CI overview.}
\end{figure}

The papers identified using the research protocol defined in the
previous section that give us an overview of the current state of the
art in build analytics domain are:

\begin{itemize}
\tightlist
\item
  Hitlon et al. 2016
\item
  Rausch et al. 2017
\item
  Fowler et al. 2006
\item
  Stolberg et al. 2009
\item
  Beller et al. 2017
\end{itemize}

The topics that are being explored are:

\begin{itemize}
\tightlist
\item
  usage of CI in the industry by \citet{hilton2016usage}
\item
  growing popularity of CI due to the introduction of VCS as suggested
  by \citet{rausch2017empirical}
\item
  common practices used in the industry exemplified by
  \citet{fowler2006continuous}
\item
  use of common CI practice in the agile approach presented by
  \citet{stolberg2009enabling}
\end{itemize}

The practice that are being proposed are:

\begin{itemize}
\tightlist
\item
  Maintain a Single Source Repository
\item
  Automate the Build
\item
  Make Your Build Self-Testing
\item
  Everyone Commits To the Mainline Every Day
\item
  Every Commit Should Build the Mainline on an Integration Machine
\item
  Fix Broken Builds Immediately
\item
  Keep the Build Fast
\item
  Test in a Clone of the Production Environment
\item
  Make it Easy for Anyone to Get the Latest Executable
\item
  Everyone can see what's happening
\item
  Automate Deployment
\end{itemize}

A survey conduced in open-source projects by \citet{hilton2016usage}
indicated that 40\% of all projects used CI. It observed that a median
project introduces CI a year into development. Furthermore, the paper
claims that CI is widely used in practise nowadays. The paper by
\citet{rausch2017empirical} explores how CI is widely available for
projects of every size with the introduction of Version Control Systems
(VCS) such as GitHub, and hosted build automation platforms such as
Travis. In this way, CI adoption rates will increase further in the
future.

This is an overview of CI and how it works in daily life. Maintaining
this system requires engineers to follow fundamental practises presented
by \citet{fowler2006continuous}. The practises presented by
\citet{fowler2006continuous} are still commonly used today, particularly
in the agile software industry as suggested by
\citet{stolberg2009enabling}. Below is an explanation of each of the
practices suggested by \citet{fowler2006continuous}.

\emph{Maintain a Single Source Repository}

The practice advocates the use of a revision control system for the
project's source code. All artefacts required to build the project
should be placed in a single repository. This ensures that the system
does not require additional dependencies. It is preferred for changes to
be integrated at least once a day. This makes it easier to find and
remove bugs.

\emph{Automate the Build}

A single command should have the capability of building the system. A
build script should be able to compile code, execute unit tests and
automate integration. Many build tools are frequently used in continuous
integration environments. Other functions that the build may include are
code quality checks, semantic checks and measuring technical debt etc.

\emph{Make Your Build Self-Testing} Once the code is built, all tests
should run to confirm that it behaves as the developer would expect it
to behave.

\emph{Everyone Commits To the Mainline Every Day}

This is one of the most important rules presented by
\citet{fowler2006continuous}. By committing regularly, every developer
can reduce the number of conflicting changes. Checking in large data
runs thee risk of conflicting with other features and can be very
challenging to resolve. Committing all changes at least once a day is an
integral practice of the CI framework. In addition, performing nightly
builds in recommended.

\emph{Every Commit Should Build the Mainline on an Integration Machine}

The system should build commits to the current working version to ensure
that they integrate correctly. A ``nightly build'' should also execute
at a scheduled time every night. This build should include more
verifications than the ones on other branches. It takes longer to run
and is executed less frequently.

\emph{Fix Broken Builds Immediately}

A broken build is anything that prevents the build from reporting
success. This could be a compilation error, failed test or inspection,
problem with the database or failed deployment. In the CI environment,
it is important that these problems are fixed immediately.

\emph{Keep the Build Fast}

The build should complete rapidly, so if there is an issue with
integration, it can be identified quickly. A good practice is to have
more fast-executing tests than slow tests. This means that you need to
have more unit tests than other types of tests.

\emph{Test in a Clone of the Production Environment}

Having a test environment can lead to failures in tested systems when
they deploy in the production environment. This is because the
production environment may differ from the test environment. However,
building a replica of a production environment is cost effective.
Thereby, testing in a clone of the production environment ensures that
your project is improving and not decaying.

\emph{Make it Easy for Anyone to Get the Latest Executable}

Builds should be readily available to stakeholders and testers as this
can reduce the amount of rework required when rebuilding a feature that
does not meet requirements. In general, all programmers should start the
day by updating the project from the repository to ensure everyone is up
to date.

\emph{Everyone can see what's happening} It should be easy to find out
whether the build breaks and what/who made relevant changes.

\emph{Automate Deployment} It is important to write a script to deploy
the application to a live test server that everyone can look at.

It is important to note that CI does not get rid of bugs, but it does
make them dramatically easier to find and remove. The above practises
are important for the smooth functioning of CI framework.

\textbf{RQ3}: What future research can we expect in the field of build
analytics?

Currently research on build analytics is limited by some challenges,
some are specific to build analytics and some are applicable to the
entire field of software engineering.

The papers identified using the research protocol defined in section
\ref{build-analytics-research-protocol} that give us an overview of
challenges and future research in the field of build analytics are:

\begin{itemize}
\tightlist
\item
  \citet{bisong2017built}
\item
  \citet{pinto2018work}
\item
  \citet{santolucito2018statically}
\item
  \citet{baltes2018no}
\item
  \citet{zhao2017impact}
\item
  \citet{vassallo2018break}
\item
  \citet{beller2017oops}
\end{itemize}

In \citet{bisong2017built} the main limitation was the performance of
the machine learning algorithm used. In the implementation R was used
and it proved not capable of processing the amounts of data needed. This
shows that it is important to choose the right tool when analyzing data.

\citet{pinto2018work} notes that it's research and many others are done
on open source software. There are still a lot of possibilities for
researching on proprietary software projects.

Tools presented in papers might require a more large scale and long term
study to verify that the tool presented keeps up when it is actually
used \citep{santolucito2018statically}.

Future research in build analytics branches in a couple of different
topics. \citet{pinto2018work} proposes to focus on getting a better
understanding of the users and why they might choose to abandon an
automatic build platform.

\citet{baltes2018no} suggests that in future research more perspectives
when analyzing commit data should be taken into account, for instance
partitioning commits by developer. It also notes the importance of more
qualitative research.

Some open research questions from recent papers are the following:

\begin{itemize}
\tightlist
\item
  How do teams change their pull request review practices in response to
  the introduction of continuous integration? \citep{zhao2017impact}
\item
  How can we detect if fixing a build configuration requires changes in
  the remote environment? \citep{vassallo2018break}
\item
  Does breaking the build often translate to worse project quality and
  decreased productivity? \citep{beller2017oops}
\end{itemize}

From the synthesis of the works discussed in this section the following
research questions emerged:

\begin{itemize}
\tightlist
\item
  What is the impact of the choice of Continuos Integration platform?
  Most of the research is done on users using Travis~CI, there are many
  other platforms out there. Every platform has their own
  characteristics and this could impact the effectiveness for a specific
  kind of project.
\end{itemize}

\chapter{Bug Prediction}\label{bug-prediction}

\section{Motivation}\label{motivation-2}

Minimizing the number of bugs in software is an effort central to
software engineering - faulty code fails to fullfill the purpose it was
written for, its impact ranges from sligthly embarrassing to disastrous
and dangerous, and last but not least - fixing it costs time and money.
Resources in a software development lifecycle are almost always limited
and therefore should be allocated to where they are needed most - in
order to avoid bugs, they should be focused on the most fault-prone
areas of the project. Being able to predict where such areas might be
would allow more development and testing efforts to be allocated on the
right places.

However, as noted in \citet{DAmbros2012}, reliably predicting which
parts of source code are the most fault-prone is one of the holy-grails
of software engineering. Thus it is not surprising that bug-prediction
continues to garner a widespread research interest in software
analytics, now equipped with the ever-expanding toolbox of data-mining
and machine learning techniques. In this survey we investigate the
current efforts in bug-prediction in the light of the advances in
software analytics methods and focus our attention on answering the
following research questions:

\begin{itemize}
\tightlist
\item
  \textbf{RQ1} What is the current state of the art in bug prediction?
  More specifically, we aim to answer the following:

  \begin{itemize}
  \tightlist
  \item
    What software or other metrics does bug prediction rely on and how
    good are they?
  \item
    What kind prediction models are predominantly used?
  \item
    How are bug prediction models and results validated and evaluated?
  \end{itemize}
\item
  \textbf{RQ2} What is the current state of practice in bug prediction?

  \begin{itemize}
  \tightlist
  \item
    Are bug prediction techniques applied in practice and if so, how?
  \item
    Are the current developments in the field able to provide actionable
    tools for developers?
  \end{itemize}
\item
  \textbf{RQ3} What are some of the open challenges and directions for
  future research?
\end{itemize}

\section{Research protocol}\label{research-protocol-1}

We started by studying the initial 6 seed papers which were selected
based on domain knowledge:

\begin{itemize}
\tightlist
\item
  \citet{Gyimothy2005}
\item
  \citet{Catal2009review}
\item
  \citet{Arisholm2010}
\item
  \citet{DAmbros2010}
\item
  \citet{Hall2012}
\item
  \citet{Lewis2013}
\end{itemize}

Our searches were based on the following elements:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Keyword search using search engines (Scopus, ACM Digital Library, IEEE
  Explorer). The search query was constructed so that the paper title
  had to contain the phrase bug prediction, but also the other more
  general variants used in literature: \emph{bug/defect/fault
  prediction}. The title also had to contain at least one of following
  keywords: \emph{metrics}, \emph{models}, \emph{validation},
  \emph{evaluation}, \emph{developers}. To remain within the bug
  prediction field we required \emph{software} to appear in the
  abstract.
\item
  Filtering search results by publication date. We excluded papers older
  than 10 years; that is, published before 2008.
\item
  Filtering by the number of citations. We selected papers with 10 or
  more citations in order to focus on the ones that already have some
  visibility within the field.
\item
  Exploring other impactful publications by the same authors.
\end{enumerate}

\emph{Table 1. Papers found by investigating the authors of other
papers.}

\begin{longtable}[]{@{}lll@{}}
\toprule
Starting point & Type & Result\tabularnewline
\midrule
\endhead
\citet{DAmbros2010} & is author of & \citet{DAmbros2012}\tabularnewline
\citet{Catal2009review} & is author of & \citet{Catal2011}
\citet{Catal2009investigating}\tabularnewline
\bottomrule
\end{longtable}

\section{Answers}\label{answers-1}

\chapter{Ecosystem Analytics}\label{ecosystem-analytics}

\section{Motivation}\label{motivation-3}

In the modern day and age, the majority of software products make use of
external software or libraries to use the functionality of these
products, without having to develop this functionality itself. Moreover,
multiple languages, such as Python and Rust, provide package managers
(pip\footnote{\url{https://pypi.org/project/pip/}} and Cargo\footnote{\url{https://crates.io/}}
respectively) which can be used to easily manage this third-party
functionality, as well as distribute it.

Together with this comes the growth in open source projects. On
platforms such as GitHub\footnote{\url{https://github.com:}}, it is easy
and quick to create a new software product, which can be developed,
reviewed and used by the whole community.

This in turn leads to intertwined landscapes of software products, which
are deemed a \emph{software ecosystems}. As stated by
\citet{Messerschmitt2003}, a \emph{software ecosystem} is ``a collection
of software products that have some given degree of symbiotic
relationships.'' Another, similar definition is given by
\citet{Lungu2009}: ``A software ecosystem is a collection of software
projects which are developed and co-evolve in the same environment.''
\citet{Mens2013} extends this definition, ``by explicitly considering
the communities involved (e.g.~user and developer communities) as being
part of the software ecosystem.''

By performing analysis on these software ecosystems, people aim to
generate meaningful insights, which can then be used to improve the
efficiency and effectivity of the software development process
throughout the lifecycle of the developed software.

In order to perform a survey on the current progress in the field of
software ecosystem analytics, we have formulated three research
questions:

\begin{itemize}
\tightlist
\item
  \textbf{RQ1}: What is the current state of the art in software
  analytics for ecosystem analytics?
\item
  \textbf{RQ2}: What is the current state of practice in software
  analytics for ecosystem analytics?
\item
  \textbf{RQ3}: What are the open challenges in ecosystem analytics, for
  which future research is required?
\end{itemize}

Each of these research questions will be answered, using recent papers
written in this field of research.

\section{Research Protocol}\label{research-protocol-2}

In order to select literature to answer the research questions given in
the previous section, the survey method suggested by
\citet{Kitchenham2004} is used. This method creates a systematic way to
select a set of papers, which is relevant to the research question(s).

The search strategy, as described by \citet{Kitchenham2004}, are usually
iterative and benefit from consultations with experts in the field,
amongst other things. Our search strategy can be split in three
different types:

\begin{itemize}
\tightlist
\item
  the initial seed, given by an expert in the field, MSc. Joseph
  Hejderup
\item
  a search using a digital search engine, namely Google
  Scholar\footnote{\url{https://github.com:}}
\item
  a selection of referenced papers within papers selected before in the
  above two searches
\end{itemize}

\subsection{Initial seed}\label{initial-seed}

The first type is quite straightforward. To give this survey a head
start, MSc. Joseph Hejderup has provided us with a total of thirteen
papers, as shown in Table 1.

As each of these papers come from an expert in the field, each paper is
assumed to be relevant to atleast the field of software ecosystems.
Because of this, each of these papers were judged on their relevance to
either of the research questions. In Table 1, this relevance judgment is
shown in the left column, since a paper is only selected, if the paper
is indeed relevant. Table 2 describes the reason for which each
particular paper is not selected for the literature survey.

\begin{longtable}[]{@{}lllll@{}}
\toprule
\begin{minipage}[b]{0.01\columnwidth}\raggedright\strut
Selected\strut
\end{minipage} & \begin{minipage}[b]{0.09\columnwidth}\raggedright\strut
Author(s)\strut
\end{minipage} & \begin{minipage}[b]{0.34\columnwidth}\raggedright\strut
Title\strut
\end{minipage} & \begin{minipage}[b]{0.02\columnwidth}\raggedright\strut
Year\strut
\end{minipage} & \begin{minipage}[b]{0.39\columnwidth}\raggedright\strut
Keywords\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
-\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
\citet{Abate2009}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Strong dependencies between software components\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2009\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
-\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
\citet{Abate2011}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Predicting upgrade failures using dependency analysis\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2011\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
\citet{Abdalkareem2017}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Why do developers use trivial packages? An empirical case study on
NPM\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2017\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
JavaScript; Node.js; Code Reuse; Empirical Studies\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
\citet{Bogart2016}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
How to break an api: Cost negotiation and community values in three
software ecosystem\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2016\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
Software ecosystems; Dependency management; semantic versioning;
Collaboration; Qualitative research\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
\citet{Claes2015}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
A historical analysis of Debian package incompatibilities\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2015\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
debian, conflict, empirical, analysis, software, evolution,
distribution, package, dependency, maintenance\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
\citet{Constantinou2017}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
An empirical comparison of developer retention in the RubyGems and NPM
software ecosystems\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2017\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
Software ecosystem, Socio-technical interaction, Software evolution,
Empirical analysis, Survival analysis\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
\citet{Hejderup2018}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Software Ecosystem Call Graph for Dependency Management\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2018\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
\citet{Kikas2017}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Structure and evolution of package dependency networks\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2017\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
\citet{Kula2017}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Do developers update their library dependencies?\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2017\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
Software reuse, Software maintenance, Security vulnerabilities\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
-\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
\citet{Mens2013}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Studying Evolving Software Ecosystems based on Ecological Models\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2013\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
Coral Reef, Natural Ecosystem, Open Source Software, Ecological Model,
Software Project\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
\citet{Raemaekers2017}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Semantic versioning and impact of breaking changes in the Maven
repository\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2017\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
Semantic versioning, Breaking changes, Software libraries\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
\citet{Robbes2012}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
How do developers react to API deprecation? The case of a smalltalk
ecosystem\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2012\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
Ecosystems, Mining Software Repositories, Empirical Studies\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.01\columnwidth}\raggedright\strut
+\strut
\end{minipage} & \begin{minipage}[t]{0.09\columnwidth}\raggedright\strut
\citet{Trockman2018}\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Adding sparkle to social coding: An empirical study of repository badges
in the npm ecosystem\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2018\strut
\end{minipage} & \begin{minipage}[t]{0.39\columnwidth}\raggedright\strut
\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\emph{Table: 1. Papers provided by MSc. Joseph Hejderup. The first
column describes whether the paper of the row will be used. A `+' means
it will be used, a `-' means it will not.}

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.05\columnwidth}\raggedright\strut
Paper Reference\strut
\end{minipage} & \begin{minipage}[b]{0.05\columnwidth}\raggedright\strut
Reason not selected\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
\citet{Abate2009}\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
This paper seems to delve more into the software itself whereas we are
more interested in the surrounding ecosystems\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
\citet{Abate2011}\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
Kind of the same reason as \citet{Abate2009}, again we are more
interested in the surrounding ecosystems\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
\citet{Mens2013}\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
We were in doubt over this one, it could be useful but we weren't
convinced that it was. Since we already had a lot of material we decided
to not use this\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\emph{Table: 2. Papers from the initial seed that were not selected for
the literature survey, along with a specification of the reason why this
is the case.}

\subsection{Digital Search Engine}\label{digital-search-engine}

The second strategy type which is used to select relevant papers for
this literature study, is by a digital search engine. In this literature
survey, Google Scholar\footnote{\url{https://github.com:}} is used. The
following queries have been used to search for relevant papers:

\begin{itemize}
\tightlist
\item
  ``software ecosystems'' AND ``empirical analysis'' \emph{(2018)}
\item
  ``engineering software ecosystems'' \emph{(2014)}
\item
  ``software ecosystem'' AND ``empirical'' \emph{(2014)}
\item
  ``software ecosystem analytics'' \emph{(2014)}
\item
  ``software ecosystem'' AND ``analysis'' \emph{(2017)}
\item
  ``software ecosystem'' AND ``empirical'' \emph{(2018)}
\end{itemize}

For each of these queries, the results were first filtered by the
publish year. These are described by the italic year after each query
above. The papers that are filtered are published earlier than the set
publish year.

After this filtering, we first determined whether a paper was relevant
to the literature survey by examining the title. If it was unclear
whether the paper was indeed relevant by only looking at the title, the
abstract of the paper was examined closely. On these two criteria, each
of the selected papers were judged and ultimately selected. The selected
paper using these method can be found in Table 3.

\begin{longtable}[]{@{}lllll@{}}
\toprule
\begin{minipage}[b]{0.05\columnwidth}\raggedright\strut
First Author\strut
\end{minipage} & \begin{minipage}[b]{0.31\columnwidth}\raggedright\strut
Title\strut
\end{minipage} & \begin{minipage}[b]{0.02\columnwidth}\raggedright\strut
Year\strut
\end{minipage} & \begin{minipage}[b]{0.34\columnwidth}\raggedright\strut
Keywords\strut
\end{minipage} & \begin{minipage}[b]{0.13\columnwidth}\raggedright\strut
Query Used\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
\citet{Decan2018}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
An empirical comparison of dependency network evolution in seven
software packaging ecosystems\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2018\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Software repository mining, Software ecosystem, Package manager,
Dependency network, Software evolution\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
``software ecosystems'' AND ``empirical analysis''\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
\citet{Dittrich2014}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Software engineering beyond the project -- Sustaining software
ecosystems\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2014\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
engineering software ecosystems\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
\citet{Hora2016}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
How do developers react to API evolution? A large-scale empirical
study\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2016\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
API evolution, API deprecation, Software ecosystem, Empirical
study\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
``software ecosystem'' AND ``empirical''\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
\citet{Izquierdo2018}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Software Development Analytics for Xen: Why and How\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2018\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Companies, Ecosystems, Software, Measurement, Object recognition,
Monitoring, Virtualization\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
software ecosystem analytics\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
\citet{Jansen2014}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Measuring the Health of Open Source Software Ecosystems: Beyond the
Scope of Project Health\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2014\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
``open source software ecosystems''\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
\citet{Kula2017-2}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
An exploratory study on library aging by monitoring client usage in a
software ecosystem\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2017\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
``software ecosystem'' AND ``analysis''\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
\citet{Malloy2018}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
An empirical analysis of the transition from Python 2 to Python 3\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2018\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Python programming, Programming language evolution, Compliance\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
``software ecosystem'' AND ``empirical''\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
\citet{Manikas2016}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Revisiting software ecosystems Research: A longitudinal literature
study\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2016\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Software ecosystems; Longitudinal literature study; Software ecosystem
maturity\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
``Software ecosystems'' OR ``Dependency management'' OR ``semantic
version''\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
\citet{Rajlich2014}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Software evolution and maintenance\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2014\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
Software Evolution and Maintenance\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.05\columnwidth}\raggedright\strut
\citet{Teixeira2015}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Lessons learned from applying social network analysis on an industrial
Free/Libre/Open Source Software Ecosystem\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2015\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright\strut
Social network analysis Open source Open-coopetition Software ecosystems
Business models Homophily Cloud computing OpenStack\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright\strut
``software ecosystem analytics''\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\emph{Table: 3. Papers selected from searches using Google Scholar. The
column ``Query Used'' describes which of the queries is used to retrieve
the paper.}

\subsection{Referenced papers}\label{referenced-papers}

Finally, a selection of papers has been made by looking at the
references found in papers selected using the two methods above. For
these papers, the selection process is similar to that of the selected
papers using the digital search engine; it is selected when both the
title and the abstract are deemed relevant to the research questions.
This has led to the papers in Table 4. being selected.

\begin{longtable}[]{@{}lllll@{}}
\toprule
\begin{minipage}[b]{0.12\columnwidth}\raggedright\strut
First Author\strut
\end{minipage} & \begin{minipage}[b]{0.31\columnwidth}\raggedright\strut
Title\strut
\end{minipage} & \begin{minipage}[b]{0.02\columnwidth}\raggedright\strut
Year\strut
\end{minipage} & \begin{minipage}[b]{0.24\columnwidth}\raggedright\strut
Keywords\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\raggedright\strut
Referenced In\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
\citet{Bavota2014}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
How the Apache community upgrades dependencies: an evolutionary
study\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2014\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright\strut
Software Ecosystems · Project dependency upgrades · Mining software
repositories\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
\citet{Kula2017}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
\citet{Blincoe2015}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Ecosystems in GitHub and a method for ecosystem identification using
reference coupling.\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2015\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
\citet{Constantinou2017}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
\citet{Cox2015}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Measuring Dependency Freshness in Software Systems\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2015\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
\citet{Kikas2017}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
\citet{Decan2017}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
An empirical comparison of dependency issues in OSS packaging
ecosystems\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2017\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
\citet{Abdalkareem2017}, \citet{Constantinou2017},
\citet{Decan2018}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
\citet{Dietrich2014}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Broken Promises - An Empirical Study into Evolution Problems in Java
Programs Caused by Library Upgrades\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2014\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
\citet{Raemaekers2017}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
\citet{Malloy2017}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
Quantifying the transition from Python 2 to 3: an empirical study of
Python applications.\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2017\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
\citet{Malloy2018}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.12\columnwidth}\raggedright\strut
\citet{McDonnell2013}\strut
\end{minipage} & \begin{minipage}[t]{0.31\columnwidth}\raggedright\strut
An empirical study of api stability and adoption in the android
ecosystem\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright\strut
2013\strut
\end{minipage} & \begin{minipage}[t]{0.24\columnwidth}\raggedright\strut
\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright\strut
\citet{Manikas2016}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\emph{Table: 4. Papers selected which are referenced in previously
selected papers. The column ``Referenced In'' describes in which
selected paper the paper is referenced.}

\section{Answers}\label{answers-2}

\chapter{Release Engineering
Analytics}\label{release-engineering-analytics}

\section{Motivation}\label{motivation-4}

Release engineering is a discipline involved with making software
available for end users. Efforts spent within the development
environment of a software system should eventually be integrated and
deployed such that end users may benefit from them. In recent years,
release engineers have developed and adopted techniques to build
infrastructures and pipelines which automate the process of releasing
software to an increasingly large degree. These modern approaches have
resulted in various practices such as releasing new versions of a
software system in significantly shorter cycles.

Due to these developments being industry-driven, release engineering
forms a largely uncharted territory for software engineering research.
It requires the attention from researchers both because these new
practices have an often unanticipated impact on software studies and
because they require empirical validation \citep{adams2016a}.

Therefore, this systematic literature review aims to provide an overview
of the software analytics research that has been conducted so far on
release engineering. Its main purpose is to identify the apparent gap
between research and practice, in order to guide further research
efforts.

\subsection{Research Questions}\label{research-questions}

Contrary to what is regularly the case, with release engineering,
practice seems to be ahead of research. Building on this idea, our
questions are constructed to identify in which ways existing modern
release engineering practices should still be studied in software
analytics research. Our review thus aims to answer the following
questions.

\begin{itemize}
\item
  \textbf{RQ 1:} \emph{How is modern release engineering done in
  practice?} This question aims to identify the so-called ``state of the
  practice'' in release engineering. We will summarize practices that
  have been adopted to drive release engineering forward. In addition we
  will identify the tools utilized to bring this about. Case studies
  will also be analyzed to this end.
\item
  \textbf{RQ 2:} \emph{What aspects of modern release engineering have
  been studied in software analytics research so far?} In order to
  answer this question we investigate the practices that previous
  empirical studies have focused on. In doing so, we identify the
  associated costs and benefits that have been found, and the analysis
  methods used.
\item
  \textbf{RQ 3:} \emph{What aspects of modern release engineering make
  for relevant study objects in future software analytics research?} In
  answering this question we aim to identify the gap between practice
  and research in release engineering. This way, our intent is not only
  to guide but also to motivate future research.
\end{itemize}

\section{Research Protocol}\label{research-protocol-3}

In this section, we will describe\ldots{}

\subsection{Search Strategy}\label{search-strategy}

Since release engineering is a relatively new research topic, we took an
exploratory approach in collecting any literature revolving around the
topic of release engineering from the perspective of software analytics.
This aided us in determining a more narrow scope for our survey,
subsequently allowing us to find additional literature fitting this
scope.

At the start of this project, we were provided with an initial seed of
five papers as a starting point for our literature survey. These initial
papers were \citet{adams2016a}, \citet{da2016a}, \citet{d2014a},
\citet{khomh2012a}, and \citet{khomh2015a}.

We collected publications using two search engines: Scopus and Google
Scholar. These each encompass various databases such as ACM Digital
Library, Springer, IEEE Xplore and ScienceDirect. The main query that we
constructed is displayed in Figure 1. The publications found using this
query were:

\begin{itemize}
\tightlist
\item
  \citet{kaur2019a}
\item
  \citet{kerzazi2013a}
\item
  \citet{castelluccio2017a}
\item
  \citet{karvonen2017a}
\item
  \citet{claes2017a}
\item
  \citet{fujibayashi2017a}
\item
  \citet{souza2015a}
\item
  \citet{laukkanen2018a}
\end{itemize}

\begin{verbatim}
TITLE-ABS-KEY(
  (
    "continuous release" OR "rapid release" OR "frequent release"
    OR "quick release" OR "speedy release" OR "accelerated release"
    OR "agile release" OR "short release" OR "shorter release"
    OR "lightning release" OR "brisk release" OR "hasty release"
    OR "compressed release" OR "release length" OR "release size"
    OR "release cadence" OR "release frequency"
    OR "continuous delivery" OR "rapid delivery" OR "frequent delivery"
    OR "fast delivery" OR "quick delivery" OR "speedy delivery"
    OR "accelerated delivery" OR "agile delivery" OR "short delivery"
    OR "lightning delivery" OR "brisk delivery" OR "hasty delivery"
    OR "compressed delivery" OR "delivery length" OR "delivery size"
    OR "delivery cadence" OR "continuous deployment" OR "rapid deployment"
    OR "frequent deployment" OR "fast deployment" OR "quick deployment"
    OR "speedy deployment" OR "accelerated deployment" OR "agile deployment"
    OR "short deployment" OR "lightning deployment" OR "brisk deployment"
    OR "hasty deployment" OR "compressed deployment" OR "deployment length"
    OR "deployment size" OR "deployment cadence"
  ) AND (
    "release schedule" OR "release management" OR "release engineering"
    OR "release cycle" OR "release pipeline" OR "release process"
    OR "release model" OR "release strategy" OR "release strategies"
    OR "release infrastructure"
  )
  AND software
) AND (
    LIMIT-TO(SUBJAREA, "COMP") OR LIMIT-TO(SUBJAREA, "ENGI")
)
AND PUBYEAR AFT 2014
\end{verbatim}

\emph{Figure 1. Query used for retrieving release engineering
publications via Scopus.}

In addition to querying search engines as described above, references
related to retrieved papers were analyzed. For each paper, the review
concerned the publications cited by the paper, as well as those citing
the paper. These reference lists were obtained from Google Scholar and
from the reference lists in the papers themselves. The results of the
reference analysis are listed in Table 1.

\emph{Table 1. Papers found indirectly by investigating citations of/by
other papers.}

\begin{longtable}[]{@{}lll@{}}
\toprule
Starting point & Type & Result\tabularnewline
\midrule
\endhead
\citet{souza2015a} & has cited & \citet{plewnia2014a}
\citet{mantyla2015a}\tabularnewline
\citet{khomh2015a} & is cited by & \citet{poo-caama2016a}
\citet{teixeira2017a}\tabularnewline
\citet{mantyla2015a} & is cited by & \citet{rodriguez2017a}
\citet{cesar2017a}\tabularnewline
\bottomrule
\end{longtable}

All the papers that were found, were stored in a custom built web-based
tool for conducting literature reviews. The source code of this tool is
published in a \href{https://github.com/jessetilro/research}{GitHub
repository}. The tool was hosted on a virtual private server, such that
all retrieved publications were stored centrally, accessible to all
reviewers.

\subsection{Study Selection}\label{study-selection}

In the utilized tool for conducting the survey, it is possible to label
papers with tags and leave comments and ratings. Every paper is reviewed
based on the selection criteria. Based on this, the tool allowed to
filter out all papers that appeared not to be relevant for this
literature survey.

The selection criteria are as follows:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The study must show (at least) one release engineering technique.
\item
  The study must not just show a release engineering technique, but
  analyze its performance compared to other techniques.
\end{enumerate}

Based on these selection criteria, the following papers appeared to be
irrelevant for the scope of this survey:

\begin{itemize}
\tightlist
\item
  {[}link to paper{]} - Excluded based on rule 2.
\end{itemize}

\subsection{Study Quality Assessment}\label{study-quality-assessment}

Based on \citet{kitchenham2004procedures}, the quality of a paper will
be assessed by the evidence it provides, based on the following scale.
All levels of quality will be accepted, except for level 5 (expert
opinion).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Evidence obtained from at least one properly-designed randomised
  controlled trial.
\item
  Evidence obtained from well-designed pseudo-randomised controlled
  trials (i.e.~non-random allocation to treatment).
\item
  Comparative studies in a real-world setting:

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    Evidence obtained from comparative studies with concurrent controls
    and allocation not randomised, cohort studies, case-control studies
    or interrupted time series with a control group.
  \item
    Evidence obtained from comparative studies with historical control,
    two or more single arm studies, or interrupted time series without a
    parallel control group.
  \end{enumerate}
\item
  Experiments in artificial settings:

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    Evidence obtained from a randomised experiment performed in an
    artificial setting.
  \item
    Evidence obtained from case series, either post-test or
    pre-test/post-test.
  \item
    Evidence obtained from a quasi-random experiment performed in an
    artificial setting.
  \end{enumerate}
\item
  Evidence obtained from expert opinion based on theory or consensus.
\end{enumerate}

Also, the studies will be examined to see if they contain any type of
bias. For this, the same types of biases will be used as described by
\citet{kitchenham2004procedures}:

\begin{itemize}
\tightlist
\item
  Selection/Allocation bias: Systematic difference between comparison
  groups with respect to treatment.
\item
  Performance bias: Systematic difference is the conduct of comparison
  groups apart from the treatment being evaluated.
\item
  Measurement/Detection bias: Systematic difference between the groups
  in how outcomes are ascertained.
\item
  Attrition/Exclusion bias: Systematic differences between comparison
  groups in terms of withdrawals or exclusions of participants from the
  study sample.
\end{itemize}

The studies will be labeled by their quality level and possible biases.
This information can be used during the Data Synthesis phase to weigh
the importance of individual studies \citep{kitchenham2004procedures}.

\subsection{Data Extraction}\label{data-extraction}

To accurately capture the information contributed by each publication in
our survey, we will use a systematic approach to extracting data. To
guide this process, we will be using a data extraction form which
describes what aspects of a publication are crucial to record. Besides
general publication information (title, author etc.), the form contains
questions that are based on our defined research questions. Furthermore,
the form contains a section for quantitative research, where aspects
such as population and evaluation will be documented. The form that is
used for this is shown below:

\begin{verbatim}
General information:
    Name of person extracting data:
    Date form completed (dd/mm/yyyy):
    Publication title:
    Author information:
    Journal:
    Publication type:
    Type of study:

What practices in release engineering does this publication mention?

Are these practices to be classified under dated, state of the art or state of
the practice? Why?

What open challenges in release engineering does this publication mention?

What research gaps does this publication contain?

Are these research gaps filled by any other publications in this survey?

Quantitative research publications:
    Study start date:
    Study end date or duration:
    Population description:
    Method(s) of recruitment of participants:
    Sample size:
    Evaluation/measurement description:
    Outcomes:
    Limitations:
    Future research:

Notes:
\end{verbatim}

\subsection{Data Synthesis}\label{data-synthesis}

To summarize the contributions and limitations of each of the included
publications, we will apply a descriptive synthesis approach. In this
part of our survey, we will compare the data that was extracted of the
included publications. Publications with similar findings will be
grouped and evaluated, and differences between groups of publications
will be structured and elaborated on. In this we will compare them using
specifics such as their study types, time of publication and study
quality.

If the extracted data allows for a structured tabular visualization of
similarities and differences between publications this we serve as an
additional form of synthesis. However, this depends on the final
included publications of this survey.

\subsection{Included and Excluded
Studies}\label{included-and-excluded-studies}

\subsection{Project timetable}\label{project-timetable}

The literature review was conducted over the course of four weeks. We
worked iteratively and planned for four weekly milestones.

\begin{longtable}[]{@{}lll@{}}
\toprule
\begin{minipage}[b]{0.22\columnwidth}\raggedright\strut
Milestone\strut
\end{minipage} & \begin{minipage}[b]{0.18\columnwidth}\raggedright\strut
Deadline\strut
\end{minipage} & \begin{minipage}[b]{0.48\columnwidth}\raggedright\strut
Goals\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.22\columnwidth}\raggedright\strut
Milestone 1\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
16/9/18\strut
\end{minipage} & \begin{minipage}[t]{0.48\columnwidth}\raggedright\strut
- Develop the search strategy - Collect initial publications\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright\strut
Milestone 2\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
23/9/18\strut
\end{minipage} & \begin{minipage}[t]{0.48\columnwidth}\raggedright\strut
Write full research protocol\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright\strut
Milestone 3\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
30/9/18\strut
\end{minipage} & \begin{minipage}[t]{0.48\columnwidth}\raggedright\strut
- Collect additional literature according to the protocol - Perform data
extraction\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.22\columnwidth}\raggedright\strut
Milestone 4\strut
\end{minipage} & \begin{minipage}[t]{0.18\columnwidth}\raggedright\strut
7/10/18\strut
\end{minipage} & \begin{minipage}[t]{0.48\columnwidth}\raggedright\strut
- Perform data synthesis - Write final version of the chapter\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\section{Answers}\label{answers-3}

\subsection{RQ1: \ldots{}}\label{rq1}

\subsection{RQ2: \ldots{}}\label{rq2}

\subsection{RQ3: \ldots{}}\label{rq3}

\section{Discussion}\label{discussion}

\section{Conclusion}\label{conclusion}

\chapter{Code Review}\label{code-review}

\section{Review protocol}\label{review-protocol}

This section describes the review protocol used for the systematic
review presented in this section. The protcol has been set up using
Kitchenham's method as described by Kitchenham et al.
\citep{kitchenham2007}.

\subsection{Research questions}\label{research-questions-1}

The goal of the review is to summarize the state of the art and identify
future challenges in the code review area. The research questions are as
follows:

\begin{itemize}
\tightlist
\item
  \textbf{RQ1}: \emph{What is the state of the art in the research area
  of code review?} This question focusses on topics that are researched
  often, the results of that research, and research methods, tools and
  datasets that are used.
\item
  \textbf{RQ2}: \emph{What is the current state of practice in the area
  of code review?} This concerns tools and techniques that are developed
  and used in practice, by open source projects but also by commercial
  companies.
\item
  \textbf{RQ3}: \emph{What are future challenges in the area of code
  review?} This concerns both research challenges and challenges for use
  in practice.
\end{itemize}

\subsection{Search process}\label{search-process}

The search process consists of the following:

\begin{itemize}
\tightlist
\item
  A Google Scholar search using the search query \emph{``modern code
  review'' OR ``modern code reviews''}. The results list will be sorted
  by decreasing relevance by Google Scholar and will be considered by us
  in order.
\item
  A general Google search for non-scientific reports (e.g., blog posts)
  and implemented code review tools. For this search queries \emph{code
  review} and \emph{code review tools} are used, respectively. The
  result list will be considered in order.
\item
  All papers in the initial seed provided by the course instructor will
  be considered.
\item
  All papers referenced by already collected papers will be considered.
\end{itemize}

From now on, all four categories listed above in general will be called
\emph{resource}.

\subsection{Inclusion criteria}\label{inclusion-criteria}

From the scientific literature, the following types of papers will be
considered:

Papers researching recent code review

\begin{itemize}
\tightlist
\item
  concepts,
\item
  methodologies,
\item
  tools and platforms,
\item
  and experiments concerning the preceding.
\end{itemize}

From non-scientific resources, all resources discussing recent tools and
techniques used in practice will be considered.

\subsection{Exclusion criteria}\label{exclusion-criteria}

Resources published before 2008 will be excluded from the study.

\subsection{Primary study selection
process}\label{primary-study-selection-process}

We will select a number of candidate resources based on the criteria
stated above. For each resource, each person participating in the review
can select it as a candidate.

From all candidates, resource will be selected that will actually be
reviewed. This can also be done by each person participating in the
review. All resources that are candidates but are not selected for
actual review must be explicitly rejected, with accompanying reasoning,
by at least two persons participating in the review.

\subsection{Data collection}\label{data-collection}

The following data will be collected from each considered resource:

\begin{itemize}
\tightlist
\item
  Source (for example, the blog website or specific journal)
\item
  Year published
\item
  Type of resource
\item
  Author(s) and organization(s)
\item
  Summary of the resource of a maximum of 100 words
\item
  Data for answering \textbf{RQ1}:

  \begin{itemize}
  \tightlist
  \item
    Sub-topic of research
  \item
    Research method
  \item
    Used tools
  \item
    Used datasets
  \item
    Research questions and their answers
  \end{itemize}
\item
  Data for answering \textbf{RQ2}:

  \begin{itemize}
  \tightlist
  \item
    Tools used
  \item
    Company/organization using the tool
  \item
    Evaluation of the tool
  \end{itemize}
\item
  Data for answering \textbf{RQ3}:

  \begin{itemize}
  \tightlist
  \item
    Future research challenges posed
  \end{itemize}
\end{itemize}

All data will be collected by one person participating in the review and
checked by another.

\section{Candidate resources}\label{candidate-resources}

In this section, all candidates that are collected using the described
search process are presented. The in survey column in the tables below
indicates whether the paper has been included in the survey in the end
or if it has been excluded for some reason. If it has been excluded, the
reason is stated along with the paper summary.

\subsection{Initial seed}\label{initial-seed-1}

These following table lists all initial seed papers provided by the
course intructor. They are listed in alphabetical order of the first
author's name, and then by publish year.

\begin{longtable}[]{@{}llll@{}}
\toprule
First author & Year & Reference & In survey? (Y/N)\tabularnewline
\midrule
\endhead
Bacchelli, A. & 2013 & \citet{bacchelli2013expectations}
&\tabularnewline
Beller, M. & 2014 & \citet{beller2014modern} &\tabularnewline
Bird, C. & 2015 & \citet{bird2015lessons} &\tabularnewline
Fagan, M. & 2002 & \citet{fagan2002design} &\tabularnewline
Gousios, G. & 2014 & \citet{gousios2014exploratory} &\tabularnewline
McIntosh, S. & 2014 & \citet{mcintosh2014impact} &\tabularnewline
\bottomrule
\end{longtable}

\subsection{Google Scholar}\label{google-scholar}

The following table lists all candidates that have been collected
through the Google Scholar search described in the search process. They
are listed in alphabetical order of the first author's name, and then by
publish year. Note that as described in the search process section,
papers in the search are considered in order.

\begin{longtable}[]{@{}llll@{}}
\toprule
First author & Year & Reference & In survey? (Y/N)\tabularnewline
\midrule
\endhead
Baysal, O. & 2016 & \citet{baysal2016investigating} &\tabularnewline
Thongtanunam, P. & 2015 & \citet{thongtanunam2015should}
&\tabularnewline
Thongtanunam, P. & 2016 & \citet{thongtanunam2016revisiting}
&\tabularnewline
Xia, X. & 2015 & \citet{xia2015should} &\tabularnewline
Zanjani, M. B. & 2016 & \citet{zanjani2016automatically}
&\tabularnewline
\bottomrule
\end{longtable}

\subsection{By reference}\label{by-reference}

The following table lists all candidates that have been found by being
referenced by another paper we found. They are listed in alphabetical
order of the first author's name, and then by publish year.

\begin{longtable}[]{@{}lllll@{}}
\toprule
First author & Year & Reference & Referenced by & In survey?
(Y/N)\tabularnewline
\midrule
\endhead
Baum & 2016 & \citet{baum2016faceted} & &\tabularnewline
Baum & 2017 & \citet{baum2017choice} & &\tabularnewline
Baysal & 2013 & \citet{baysal2013influence} & &\tabularnewline
Bosu & 2013 & \citet{bosu2013impact} & &\tabularnewline
Ciolkowski & 2003 & \citet{ciolkowski2003software} & &\tabularnewline
Czerwonka & 2015 & \citet{czerwonka2015code} & &\tabularnewline
\bottomrule
\end{longtable}

\section{Paper summaries}\label{paper-summaries}

This section contains summaries of all papers included in the survey.
They are listed in alphabetical order of first author name, and then by
year published.

\subsection{Expectations, outcomes, and challenges of modern code
review}\label{expectations-outcomes-and-challenges-of-modern-code-review}

Reference: \citet{bacchelli2013expectations}

This paper describes research about the goals and actual effects of code
reviews. Interviews and experiments have been done with people in the
programming field.

One of the main conclusions is that the main effect of doing code
reviews is that everyone involved understands the code better. This is
opposed to what the goal of code reviews is generally: discovering
errors.

\subsection{A Faceted Classification Scheme for Change-Based Industrial
Code Review
Processes}\label{a-faceted-classification-scheme-for-change-based-industrial-code-review-processes}

Reference: \citet{baum2016faceted}

The broad research questions treated in this article are: How is code
review performed in industry today? Which commonalities and variations
exist between code review processes of different teams and companies?
The article describes a classification scheme for change-based code
review processes in industry. This scheme is based on descriptions of
the code review processes of eleven companies, obtained from interviews
with software engineering professionals that were performed during a
Grounded Theory study.

\subsection{The Choice of Code Review Process: A Survey on the State of
the
Practice}\label{the-choice-of-code-review-process-a-survey-on-the-state-of-the-practice}

Reference: \citet{baum2017choice}

This paper, published in 2017, is trying to answer 3 RQs. Firstly, how
prevalent is change-based review in the industry? Secondly, does the
chance that code review remains in use increase if code review is
embedded into the process (and its supporting tools) so that it does not
require a conscious decision to do a review? Thirdly, are the intended
and acceptable levels of review effects a mediator in determining the
code review process?

\subsection{The influence of non-technical factors on code
review}\label{the-influence-of-non-technical-factors-on-code-review}

Reference: \citet{baysal2013influence}

\subsection{Investigating technical and non-technical factors
influencing modern code
review}\label{investigating-technical-and-non-technical-factors-influencing-modern-code-review}

Reference: \citet{baysal2016investigating}

\subsection{Modern code reviews in open-source projects: Which problems
do they
fix?}\label{modern-code-reviews-in-open-source-projects-which-problems-do-they-fix}

Reference: \citet{beller2014modern}

It has been researched what kinds of problems are solved by doing code
reviews. The conclusion is that 75\% are improvements in evolvability of
the code, and 25\% in functional aspects.

It has also been researched which part of the review comments is
actually followed up by an action, and which part of the edits after a
review are actually caused by review comments.

\subsection{Lessons learned from building and deploying a code review
analytics
platform}\label{lessons-learned-from-building-and-deploying-a-code-review-analytics-platform}

Reference: \citet{bird2015lessons}

A code review data analyzation platform developed and used by Microsoft
is discussed. It is mainly presented what users of the system think of
it and how its use influences development teams. One of the conclusions
is that in general, the platform has a positive influence on development
teams and their products.

\subsection{Impact of peer code review on peer impression formation: A
survey}\label{impact-of-peer-code-review-on-peer-impression-formation-a-survey}

Reference: \citet{bosu2013impact}

\subsection{Software Reviews: The State of the
Practice}\label{software-reviews-the-state-of-the-practice}

Reference: \citet{ciolkowski2003software}

To investigate how industry carries out software reviews and in what
forms, this paper con- ducted a two-part survey in 2002, the first part
based on a national initiative in Germany and the second involving
companies world- wide. Additionally, this paper also include some
fundenmental concepts of code review, such as functionalities of code
review.

\subsection{Code reviews do not find bugs: how the current code review
best practice slows us
down}\label{code-reviews-do-not-find-bugs-how-the-current-code-review-best-practice-slows-us-down}

Reference: \citet{czerwonka2015code}

As code review has many uses and benefits, the authors hope to find out
whether the current code review methods are sufficiently efficient. They
also research whether other methods may be more efficient. With
experience gained at Microsoft and with support of data, the authors
posit (1) that code reviews often do not find functionality issues that
should block a code submission; (2) that effective code reviews should
be performed by people with a specific set of skills; and (3) that the
social aspect of code reviews cannot be ignored.

\subsection{Design and code inspections to reduce errors in program
development}\label{design-and-code-inspections-to-reduce-errors-in-program-development}

Reference: \citet{fagan2002design}

This paper describes a method to thoroughly check code quality after
each step of the development process, in a heavyweight manner. It does
not really concern agile development.

The authors state that these methods do not affect the developing
process negatively, and that they work well for improving software
quality.

\subsection{An exploratory study of the pull-based software development
model}\label{an-exploratory-study-of-the-pull-based-software-development-model}

Reference: \citet{gousios2014exploratory}

This article focusses on how much pull requests are being used and how
they are used, focussing on GitHub. For example, it is concluded that
pull-request are not being used that much, that pull-requests are being
merged fast after they have been submitted, and that a pull request not
being merged is most of the time not caused by technical errors in the
pull-request.

\subsection{The impact of code review coverage and code review
participation on software quality: A case study of the qt, vtk, and itk
projects}\label{the-impact-of-code-review-coverage-and-code-review-participation-on-software-quality-a-case-study-of-the-qt-vtk-and-itk-projects}

Reference: \citet{mcintosh2014impact}

This paper focusses on the influence of doing light-weight code reviews
on software quality. In particular, the effect of review coverage (the
part of the code that has been reviewed) and review participation (a
measure for how much reviewers are involved in the review process) are
being assessed.

It turns out that both aspects improve software quality when they are
higher. Review participation is the most influential. According to the
authors there are other aspects, which they have not looked into, that
are of significant importance for the review process.

\subsection{Who should review my code? A file location-based
code-reviewer recommendation approach for modern code
review}\label{who-should-review-my-code-a-file-location-based-code-reviewer-recommendation-approach-for-modern-code-review}

Reference: \citet{thongtanunam2015should}

\subsection{Revisiting code ownership and its relationship with software
quality in the scope of modern code
review}\label{revisiting-code-ownership-and-its-relationship-with-software-quality-in-the-scope-of-modern-code-review}

Reference: \citet{thongtanunam2016revisiting}

\subsection{Who should review this change?: Putting text and file
location analyses together for more accurate
recommendations}\label{who-should-review-this-change-putting-text-and-file-location-analyses-together-for-more-accurate-recommendations}

Reference: \citet{xia2015should}

\subsection{Automatically recommending peer reviewers in modern code
review}\label{automatically-recommending-peer-reviewers-in-modern-code-review}

Reference: \citet{zanjani2016automatically}

\chapter{Runtime and Performance
Analytics}\label{runtime-and-performance-analytics}

In this chapter, we discuss the field of performance and runtime
analytics. This chapter does not cover the entire field because it is
too broad. Using Kitchenham's method \citep{kitchenham2004procedures},
we have narrowed down the scope of this survey.

For inspiration, we started reading five recent papers on runtime and
performance analytics published at top conferences. These five were
selected because the papers handle the software side of performance and
runtime analytics which is more in line with the other chapters of this
book. However, focussing on only software, the field is still very
broad. Currently, we are leaning towards a focus on performance and
runtime analytics literature regarding the Android platform. As we still
are at the start of this research, we might deviate from this initial
focus.

We have gathered a few other papers (excluding the five initial papers)
to find out if this field is suited for this survey. These papers can be
found in Figure INSERT FIGURE NUMBER HERE. To get relevant papers, we
used the following keywords: Android, performance, runtime, reliability,
synchronization, security, monitoring. Furthermore, we only retrieved
papers published at top venues, which we list here:

\begin{itemize}
\tightlist
\item
  ACM Transactions on Software Engineering Methodology (TOSEM),
\item
  Empirical Software Engineering (EMSE),
\item
  IEEE Transactions on Software Engineering (TSE),
\item
  Information and Software Technology (IST),
\item
  Journal of Systems and Software (JSS),
\item
  ACM Computing Surveys (CSUR),
\item
  Foundations of Software Engineering (SIGSOFT FSE),
\item
  International Conference on Automated Software Engineering (ASE),
\item
  Working Conference on Mining Software Repositories (MSR)
\item
  Symposium on Operating Systems Design and Implementation (OSDI)
\end{itemize}

\section{Week 1}\label{week-1}

Because we consider the five starting papers to be our inspiration, we
have chosen to briefly describe these papers by giving some basic
metrics about them (citations), summarizing them and by adding a few
notes about them. This is our initial work that we would like to expand
on in the coming weeks.

\subsection{Charting the API minefield using software telemetry
data}\label{charting-the-api-minefield-using-software-telemetry-data}

In this paper, researchers used software telemetry data from mobile
application crashes. With heuristics, they separated the API calls from
application calls so they can analyze what the most common causes for
crashes are. Top crash causes are: memory exhaustion, race conditions or
deadlocks, and missing resources. A significant percentage was not
suitable for analysis as these crashes were associated with generic
exceptions (10\%). They performed a literature search to find solutions
to the problems that cause the crashes. For each crash cause category,
an implementation recommendation is made. More specific exceptions,
non-blocking algorithms, and default resources can eliminate the most
frequent crashes. They also suggest that development tools like memory
analyzers, thread debuggers, and static analyzers can prevent many
application failures. They also propose features of execution platforms
and frameworks related to process and memory management that could
reduce application crashes.

\textbf{Remarks}

\begin{itemize}
\tightlist
\item
  Among the papers that refer to this paper or are referenced by this
  paper there are four papers that share the topic of crash data on
  mobile platforms that have been publiced to top software engineering
  venues {[}{]}.
\item
  The paper seems to be quite discerning as they evaluate their methods
  and reason about the threats to validity.
\end{itemize}

\subsection{Reproducing context-sensitive crashes of mobile apps using
crowdsourced
monitoring}\label{reproducing-context-sensitive-crashes-of-mobile-apps-using-crowdsourced-monitoring}

The mobile applications market continues to grow and many applications
are available. It is important for developers that their application
keeps working and that crashes are fixed as fast as possible to keep up
with competitors. However, the mobile market is complex as for end users
there are endless configurations of application versions, mobile
hardware and user input sequences. Therefore, it is difficult to
reproduce software crashes under the same context and conditions that
triggered the observed crash. This is why the researchers developed
MoTiF which uses machine learning to reproduce the steps the end users
take before the app crashes on the end user's phone and generates a test
suite. MoTiF also uses the crowd to validate whether the generated test
suite truly reproduces the observed crash.

\textbf{Remarks}

\begin{itemize}
\tightlist
\item
  The datasets used for the research are a bit questionable. One is
  based on simply performing a large amount of random event on the app,
  the other dataset is created by letting a group of 10 student try to
  crash the app in one hour.
\item
  Only 5 different apps have been tested.
\item
  Contains reference to ``Charting the API minefield using software
  telemetry data''.
\end{itemize}

\subsection{An exploratory study on faults in web api integration in a
large-scale payment
company}\label{an-exploratory-study-on-faults-in-web-api-integration-in-a-large-scale-payment-company}

This research explores what the implications of web API faults are, what
the most common web API faults are and best practices for API design.
The faults in API integration can be grouped in 11 causes: invalid user
input, missing user input, expired request data, invalid request data,
missing request data, insufficient permissions, double processing,
configuration, missing server data, internal and third party. Most
faults can be attributed to the invalid or missing request data, and
most API consumers seem to be impacted by faults caused by invalid
request data and third party integration. Furthermore, API consumers
most often use official API documentation to implement an API correctly,
followed by code examples. The challenges of preventing runtime problems
are the lack of implementation details, insufficient guidance on certain
aspects of the integration, insufficient understanding of the impact of
problems, and missing guidance on how to recover from errors.

\textbf{Remarks}

\begin{itemize}
\tightlist
\item
  Easy to read
\item
  Paper only considers a single API
\item
  Survey only has 40 responses
\end{itemize}

\subsection{Search-based test data generation for SQL
queries}\label{search-based-test-data-generation-for-sql-queries}

SQL queries should be tested as thoroughly as program code. However, it
is hard to generate test data for testing. Other researchers proposed
viewing this problem as a constraint solving problem, so test data could
be generated with a SAT-solver. However, strings are not supported by
current SAT-solver tools and it is a complex task to translate a query
to a satisfiability problem. In this research, the test generation
problem is treated as a search-based problem. They use random search,
biased random search and genetic algorithms (GA) to generate the data.
The methods are combined in a tool called EvSQL and the tool is tested
on more than 2000 queries. The GA method is the best and is able to
cover a little over 98\% of the queries.

\textbf{Remarks}

\begin{itemize}
\tightlist
\item
  Easy to read
\item
  Utilizes queries of 4 different systems
\item
  Generation of test data for SQL questies implies easier generation of
  unit- regression- and integration tests for SQL queries.
\end{itemize}

\subsection{Anomaly detection using program control flow graph mining
from execution
logs}\label{anomaly-detection-using-program-control-flow-graph-mining-from-execution-logs}

The paper attempts to diagnose distributed applications. For this
purpose they mine templates and their sequences from exedcution logs,
from this information they create a control flow graph. The main cause
of failures identified: making an API request to another application.
This results in many new calls to other services or even other
applications. This flow gets interrupted at some point. So when the top
level API is not working, they want to show where it goes wrong. In
earlier work, primarily metrics and logs were used to find the cause.
However these approaches struggled with many benign warnings or errors
in healthy state or faults do not manifest as errors. Manually checking
a transaction flow is also very hard. Instead, templates are used as
print statements from the source code. These represent the nodes, the
edges are the flows. This approach imposes two major challenges. One,
mining print statements is hard because parameters are different in
every log. Two, flows can happen at the simultaneously. The paper tries
to solve these challenges by applying a join on two print statements if
the statements are preceded and followed by approximately the same
steps.

\textbf{Remarks}

\begin{itemize}
\tightlist
\item
  Has a presentation on YouTube
\item
  Difficult to read
\end{itemize}

\section{Week 2}\label{week-2}

Because we are still working on the exact scope of the survey as well as
the lay-out of the chapter, we have chosen to temporarily divide the
papers by week. This will be changed later on. A more suitable focus for
this survey would be the Energy vs performance sub-domain of runtime and
performance analytics. To explore this domain we have summarized some
initial papers.

The survey on performance vs energy efficiency focuses on the following
research questions: \textbf{RQ1} What is the current state of art?
\textbf{RQ2} What is the current state of practice? \textbf{RQ3} What
are the challenges of the future work?

To answer these questions three papers are selected to form the basis of
this literature survey:

\begin{itemize}
\item
  Yepang Liu, Chang Xu, and Shing-Chi Cheung. 2014. Characterizing and
  detecting performance bugs for smartphone applications. In Proceedings
  of the 36th International Conference on Software Engineering (ICSE
  2014). ACM, New York, NY, USA, 1013-1024. DOI:
  \url{https://doi.org/10.1145/2568225.2568229}
\item
  Rui Pereira, Pedro Simão, Jácome Cunha, and João Saraiva. 2018.
  jStanley: placing a green thumb on Java collections. In Proceedings of
  the 33rd ACM/IEEE International Conference on Automated Software
  Engineering (ASE 2018). ACM, New York, NY, USA, 856-859. DOI:
  \url{https://doi.org/10.1145/3238147.3240473}
\item
  Stefanos Georgiou, Maria Kechagia, Panos Louridas, and Diomidis
  Spinellis. 2018. What are your programming language's energy-delay
  implications?. In Proceedings of the 15th International Conference on
  Mining Software Repositories (MSR '18). ACM, New York, NY, USA,
  303-313. DOI: \url{https://doi.org/10.1145/3196398.3196414}
\end{itemize}

By looking into the state of programming languages in regards to energy
performance, the state of the art will be determined, thus answering
RQ1. For the current state of practice (RQ2) literature on the topic of
energy efficiency in Android applications will be used. From both topics
the challenges and related work will be used for answering RQ3.

\textbf{Running list of domain keywords:} Programming Languages,
Energy-Delay-Product, Energy-Efficiency, Empirical study, performance
bug, testing, static analysis, Green Software, Energy-aware Software,
JCF

\subsection{What Are Your Programming Language's Energy-Delay
Implications?}\label{what-are-your-programming-languages-energy-delay-implications}

Motivated by the lack of studies that investigate the energy consumption
of software applications compared to the number of studies in the energy
efficiency of hardware, the researchers set out to investigate the
run-time performance of commonly used programming tasks in different
languages on different platforms. The paper contributes by giving a
customized and extended data set that can be used as a benchmark for
similar studies, a set of publicly available tools for measuring the
Energy Delay Product (EDP) of various programming tasks implemented in
different programming languages, an empirical study on programming
language EDP implications, by using different types of programming tasks
and software platforms, and a programming language-based ranking
catalogue, in the form of heat maps, where developers can find which
programming language to pick for particular tasks and platforms; when
energy or run-time performance are important. The research questions
which are answered are as follows: Which programming languages are the
most EDP efficient and inefficient for particular tasks? Which types of
programming languages are, on average, more EDP efficient and
inefficient for each of the selected platforms (i.e.~server, laptop and
embedded system)? How much does the EDP of each programming language
differ among the selected platforms? To answer these questions the
Rosetta Code Repository, a publicly available repository for programming
tasks, is used. It offers 868 tasks, 204 draft tasks and has
implementations in 675 programming languages. The results of the paper
are that for most tasks the compiled programming languages outperform
the interpreted ones.

\textbf{Keywords:} Programming Languages; Energy-Delay-Product;
Energy-Efficiency

\subsection{Characterizing and Detecting Performance Bugs for Smartphone
Applications}\label{characterizing-and-detecting-performance-bugs-for-smartphone-applications}

Bugs can cause significant performance degradation, which in turn may
lead to losing the competitive edge for the application. The paper is
motivated by people having little understanding for performance bugs and
the lack of effective techniques to fight these bugs. In the paper the
questions are researched what the common types of performance bugs are
in Android applications, and what impact they have on the user
experience (RQ1), how the performance bugs manifest themselves and if
their manifestation needs special input (RQ2), if performance bugs are
more difficult to debug and fix compared to non-performance bugs and
what information or tools can help with that (RQ3) and if there are
common causes of performance bugs, and if patterns can be distilled to
facilitate performance analysis and bug detection (RQ4). Answering these
questions leads to the paper making two major contributions: The first
empirical study of real-world performance bugs in smartphone
applications. The findings can help understand characteristics of
performance bugs in smartphone applications, and provide guidance to
related research. The implementation of a static code analyzer,
PerfChecker, which successfully identified performance optimization
opportunities in 18 popular Android applications. The selected Android
applications needed to have more than 10.000 downloads and own a public
bug tracking system. Furthermore there should be at least hundreds of
code revisions. These criteria provide an indicator of the popularity
and maturity of the selected applications. At first 29 Android
applications were selected, with PerfChecker successfully detecting 126
matching instances of the bug patterns in 18 of these applications. Of
these detected 126 matching instances of performance bug patterns, 68
were quickly confirmed by developers as previously unknown issues that
affect application performance.

\textbf{Keywords}: Empirical study, performance bug, testing, static
analysis.

\subsection{jStanley: Placing a Green Thumb on Java
Collections}\label{jstanley-placing-a-green-thumb-on-java-collections}

In this short paper the tool jStanley is presented. With the help of
this tool developers can obtain information and suggestions on the
energy efficiency of their Java code. jStanley is available as Eclipse
plugin. In a preliminary evaluation jStanley shows energy gains between
2\% and 17\%, and a reduction in execution time between 2\% and 13\%.

\textbf{Keywords:} Green Software, Energy-aware Software, JCF, Eclipse
Plugin

\subsection{A Study on the Energy Consumption of Android App Development
Approaches}\label{a-study-on-the-energy-consumption-of-android-app-development-approaches}

In this study, an analysis is given of the energy consumption of Android
app according to which development method was used to create them. They
look mainly at the difference between programming languages and their
respective frameworks. They measured across multiple devices, which
presented little difference between them. They also rewrote some app to
use a hybrid framework in the hopes of improving the performance vs
Energy consumption balance and they report a non-negligible improvement.

\textbf{Keywords:} Android, runtime, performance (search keywords, the
paper itself did not contain keywords)

\chapter{App Store Analytics}\label{app-store-analytics}

\section{Motivation}\label{motivation-5}

In the year 2008, the first app stores became available. These stores
have grown rapidly in size since then, with over 3 million apps in the
Google Play store alone at the time of writing {[}REFERENCE{]}. These
app stores together with the large user bases associated with them
provide software developers and researchers with valuable data. The
process of exploiting this data from app stores to gain valuable
insights is what we would call ``App Store Analytics''. Because apps
have not been around for a long time the research field of App Store
Analytics is still very young. However, because apps are used so much
nowadays it plays an important role in the field of Software
Engineering. Therefore, to get an overview of the current state of this
young research field this chapter(?) is devoted as a survey on the field
of App Store Analytics. We present three research questions to structure
this survey:

\begin{itemize}
\tightlist
\item
  \textbf{RQ1} Current state of the art in software analytics for App
  Store Analytics:

  \begin{itemize}
  \tightlist
  \item
    Topics that are being explored.
  \item
    Research methods, tools, and datasets being used.
  \item
    Main research findings, aggregated.
  \end{itemize}
\item
  \textbf{RQ2} Current state of practice in software analytics for App
  Store Analytics:

  \begin{itemize}
  \tightlist
  \item
    Tools and companies creating/employing them.
  \item
    Case studies and their findings.
  \end{itemize}
\item
  \textbf{RQ3} Open challenges and future research required.
\end{itemize}

\section{Research protocol}\label{research-protocol-4}

TODO: here are just ideas of what I'm doing but they should be properly
written

The research protocol is divided into two important parts: the articles
search process and the article selection process. In the following
paragraphs, both processes will be explained. {[}Refer to Kitchenham?{]}

\subsection{Search queries (Article search
process)}\label{search-queries-article-search-process}

Our initial seed of the papers came from the survey of the field of App
Store Analytics by Martin et al. {[}TODO: REFER to survey{]} and after
that we used the keywords \textbf{apps}, \textbf{app store}, \textbf{app
store analytics} and \textbf{app store mining} to search for other
relevant papers on Google Scholar, ACM, IEEE Xplore and pages of
individual journals (CSUR, TSE, EMSE, JSS, TOSEM, IST) and conferences
(ICSE, FSE, ASE, MSR, OSDI). From the results only articles with
relevant titles were selected and added to the list for consideration.

TODO: Include a table with journals/conferences including their full
names

\subsection{Article selection}\label{article-selection}

In order to retain only the most relevant papers to answer the research
questions, we devised a composed metric that takes into account the
number of citations and the year the paper was published. Taking these
elements the scoring scheme is the following: Citations (C): Year of
publication (Y): The metric is computed as follows: Inclusion\_metric =
C (0.5) * Y (0.5)

For each paper the previously mentioned metric was calculated and the
top 30 were selected, discarding the rest.

\subsubsection{Inclusion criteria}\label{inclusion-criteria-1}

\begin{itemize}
\tightlist
\item
  The paper was published in well established journal or conference.
\item
  Title or abstract of the paper mentions app stores, mining from app
  stores or app store analytics.
\item
  Tha paper was published in 2010 or later.
\end{itemize}

\subsubsection{Exclution criteria}\label{exclution-criteria}

\begin{itemize}
\tightlist
\item
  The paper has at least 10 citations on Google Scholar.
\item
  The paper focuses on mobile app development or is an analysis of
  arbitrary selection of apps and does not extend to the app stores as a
  whole.
\end{itemize}

\subsection{Fact extraction}\label{fact-extraction}

Taking into consideration the example presented by Kitchenham et al in
{[}reference{]}, the following data were extracted from each of the
papers: - Source (journal or conference) - Complete reference - Main
topic area - Authors information (full names, institution, and country)
- Summary (research questions and answers) - Research question / issue -
MORE?

Each one of the team members was in charge of reviewing and extracting
the data of a set of papers . Then, the extracted data was checked by
another member. The allocation of team members to the papers was random,
equally splitting the workloads.

\section{Answers}\label{answers-4}

\begin{itemize}
\item
  \textbf{RQ1} Current state of the art in software analytics for App
  Store Analytics
\item
  \textbf{RQ2} Current state of practice in software analytics for App
  Store Analytics
\item
  \textbf{RQ3} Open challenges and future research required
\end{itemize}

\section{Paper extracted data}\label{paper-extracted-data}

\subsection{API change and fault proneness: A threat to the success of
Android
apps}\label{api-change-and-fault-proneness-a-threat-to-the-success-of-android-apps}

\textbf{Source:} Conference ESEC/FSE'17 Joint Meeting of the European
Software Engineering Conference and the ACM SIGSOFT Symposium on the
Foundations of Software Engineering

\textbf{Main topic area:} using user feedback/reviews, API changes

\textbf{Authors information (full names, institution, and country):} -
Mario Linares-Vásquez - Universidad de los Andes, Colombia - Gabriele
Bavota - University of Sannio, Italy - Carlos Bernal-Cárdenas -
Universidad Nacional de Colombia, Colombia - Massimiliano Di Penta -
University of Sannio, Italy - Rocco Oliveto - University of Molise,
Italy - Denys Poshyvanyk - College of William and Mary, USA

The paper presents an empirical study that aims to corroborate the
relationship between the fault and change-proneness of APIs and the
degree of success of Android apps measured by their user ratings. For
this, the authors selected a sample of 7,097 free Android apps from the
Google Play Market and gathered information of the changes and faults
that the APIs used by them presented. Using this data and statistical
tools such as box-plots and the Mann-Whitney test, two main hypotheses
were analyzed. The first hypothesis tested the relationship between
fault-proneness (number of bugs fixed in the API) and the success of an
app. The second tested the relationship between change-proneness
(overall method changes, changes in method signatures and changes to the
set of exceptions thrown by methods) and the success of an app. Finally,
although no causal relationships between the variables can be assumed,
the paper found significant differences of the level of success of the
apps taking into consideration the change and fault-proneness of the
APIs they use.

\textbf{Research question/issue:} relationship between fault- and
change-proneness of APIs and the degree of success in Android apps.

\subsection{What would users change in my app? summarizing app reviews
for recommending software
changes}\label{what-would-users-change-in-my-app-summarizing-app-reviews-for-recommending-software-changes}

\textbf{Source:} Proceeding FSE 2016 Proceedings of the 2016 24th ACM
SIGSOFT International Symposium on Foundations of Software Engineering

\textbf{Main topic area:} using user feedback/reviews

\textbf{Authors information (full names, institution, and country):} -
Andrea Di Sorbo - University of Sannio, Italy - Sebastiano Panichella -
University of Zurich, Switzerland - Carol V. Alexandru - University of
Zurich, Switzerland - Junji Shimagaki - Sony Mobile Communications,
Japan - Corrado A. Visaggio - University of Sannio, Italy - Gerardo
Canfora - University of Sannio, Italy - Harald C. Gall - University of
Zurich, Switzerland

\textbf{Summary (research questions and answers):} The paper proposes a
new approach for analyzing App Store user reviews, deriving insights
from them. The presented solution has two components. First, the User
Reviews Model (URM) that enable the classification of users intentions
(e.g., UI improvements, bug fixes, etc.). Second, the Summarizer of User
Review Feedback (SURF). A tool that, by leveraging the URM, is capable
of generating summaries of users feedback. After evaluating the proposed
approach, TODO

\textbf{Research question/issue:} there is no approach that is able to
do, at the same time, the following: (i) determine for a large number of
reviews the speciﬁc topic discussed in the review (e.g., UI
improvements, security/licensing issues, etc.), (ii) identify the
maintenance task to perform for addressing the request stated in the
review (e.g., bug ﬁxing, feature enhancement, etc.), and (iii) present
such information in the form of a condensed, interactive and structured
agenda of recommended software changes, which is actionable for
developers. {[}Reference paper{]}

\subsection{App Store, Marketplace, Play! An Analysis of Multi-Homing in
Mobile Software
Ecosystems}\label{app-store-marketplace-play-an-analysis-of-multi-homing-in-mobile-software-ecosystems}

\textbf{Source:} Proceedings of the Fourth International Workshops on
Software Ecosystems \textbf{Main topic area:} App store ecosystem

\textbf{Authors information (full names, institution, and country):}
Sami Hyrynsalmi, University of Turku, Finland

Tuomas Mäkilä, University of Turku, Finland

Antero Järvi, University of Turku, Finland

Arho Suominen, VTT Technical Research Centre of Finland, Finland

Marko Seppänen, Tampere University of Technology, Finland

Timo Knuutila, University of Turku, Finland

\textbf{Summary (research questions and answers):} Multi-homing is not
used by many developers, where multi-homing is the strategy of releasing
your application to multiple platforms. An analysis of Google Play, App
Store and Windows Phone Store shows that not many developers use this
strategy. Next to this, the paper found that the type and popularity of
apps does not differ from those that use a single-homing strategy.

\textbf{Research question/issue:} Analysis of multi-homing in different
app stores. How much is it used by developers and is there a difference
in popularity?

\subsection{A systematic literature review: Opinion mining studies from
mobile app store user
reviews}\label{a-systematic-literature-review-opinion-mining-studies-from-mobile-app-store-user-reviews}

*Source:** Journal of Systems and Software

\textbf{Main topic area:} Opinion Mining and Requirement Engineering

\textbf{Authors information (full names, institution, and country):}
Necmiye Genc-Nayebi, École de Technologie Supérieure (ETS) - Université
du Québec, Canada Dr.~Alain Abran, École de Technologie Supérieure (ETS)
- Université du Québec, Canada

\textbf{Summary (research questions and answers):} TODO: summary

\textbf{Research question/issue:} What are the proposed solutions for
mining online opinions in app store user reviews, challenges and
unsolved problems in the domain, new contributions to software
requirements evolution and future research direction.

\subsection{The Impact of API Change and Fault-Proneness on the User
Ratings of Android
Apps}\label{the-impact-of-api-change-and-fault-proneness-on-the-user-ratings-of-android-apps}

TODO: template

The paper by Bavota et al. aims to find empirical evidence supporting
the success of apps and the relationship with change- and
fault-proneness of the underlying APIs, where the success of the app is
measured by its user rating. They performed two case studies to find
quantitative evidence using 5848 free Android apps as well as an
explanation for these results doing a survey with 45 professional
Android developers. The quantitative case study was done by comparing
the user ratings to the number of bug fixes and changes in the API that
an app uses. They found that apps with a high user rating are
significantly less change- and fault-prone than APIs used by apps with a
low user rating. In the second case study the paper found that most of
the 45 developers observed a direct relationship between the user
ratings of apps and the APIs those apps use.

\subsection{How can i improve my app? Classifying user reviews for
software maintenance and
evolution}\label{how-can-i-improve-my-app-classifying-user-reviews-for-software-maintenance-and-evolution}

TODO: template

The most popular apps in the app stores (such as Google Play or App
Store) receive thousands of user reviews per day and therefore it would
be very time demanding to go through the reviews manually to obtain
relevant information for the future development of the apps. This paper
uses a combination of Natural Language Processing Sentiment Analysis and
Text Analysis to extract relevant sentences from the reviews and to
classify them into the following categories: Information Seeking,
Information Giving, Feature Request, Problem Discovery, and Others. The
results show 75\% precision and 74\% recall when classifier (J48 using
data from NLP+SA+TA) is trained on 20\% of the data (1421 manually
labeled sentences from reviews of seven different apps) and the rest is
used for testing. The paper also states that the results do not differ
in a statistically significant manner when a different classifier is
used and shows that precision and recall can be further improved by
increasing the size of the data set.

\chapter{Final Words}\label{final-words}

We have finished a nice book on Software Analytics.

\bibliography{book.bib}


\end{document}
